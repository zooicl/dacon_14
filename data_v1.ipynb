{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T20:58:36.062842Z",
     "start_time": "2020-01-05T20:58:35.075574Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1590,
     "status": "ok",
     "timestamp": 1576286906380,
     "user": {
      "displayName": "주이클",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCWVh4nvn9788qUddhoWTl5qQoYt0bzVMDlJWUumTg=s64",
      "userId": "02708070532256873610"
     },
     "user_tz": -540
    },
    "id": "U3xmRNtgpZwi",
    "outputId": "f6e95e03-5913-4a53-9ff3-1b6cde1b5a82"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiden/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.2\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.externals import joblib \n",
    "import os\n",
    "from konlpy.tag import Mecab\n",
    "import lightgbm as lgb\n",
    "print(lgb.__version__)\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.externals import joblib \n",
    "\n",
    "import gc\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T20:58:37.288560Z",
     "start_time": "2020-01-05T20:58:36.064264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aiden/src/dacon_14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(297571, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "\n",
    "base_path = '.'\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(base_path , 'input/train.csv'), index_col=0)\n",
    "df_test = pd.read_csv(os.path.join(base_path , 'input/public_test.csv'), index_col=0)\n",
    "df_test['smishing'] = -1\n",
    "\n",
    "df_fea = pd.concat([df_train, df_test])\n",
    "df_fea.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T20:58:37.291726Z",
     "start_time": "2020-01-05T20:58:37.289556Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "uquxguHUpZwt"
   },
   "outputs": [],
   "source": [
    "# mecab = Mecab()\n",
    "# df_fea['morphs'] = df_fea['text'].apply(lambda x: mecab.morphs(x))\n",
    "# df_fea['morphs_str'] = df_fea['morphs'].apply(lambda x: ' '.join(x))\n",
    "# df_fea['nouns'] = df_fea['text'].apply(lambda x: mecab.nouns(x))\n",
    "# df_fea['nouns_str'] = df_fea['nouns'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# def pos(row):\n",
    "#     x = row['text']\n",
    "#     pos_dict = {c:0 for c in pos_cols}\n",
    "    \n",
    "#     for _, p in mecab.pos(x):\n",
    "#         for v in p.split('+'):\n",
    "#             pos_dict[v] += 1\n",
    "        \n",
    "#     return [pos_dict[k] for k in sorted(pos_dict.keys())]\n",
    "\n",
    "# pos_cols = [\n",
    "#     'EC',\n",
    "#     'EF',\n",
    "#     'EP',\n",
    "#     'ETM',\n",
    "#     'ETN',\n",
    "#     'IC',\n",
    "#     'JC',\n",
    "#     'JKB',\n",
    "#     'JKC',\n",
    "#     'JKG',\n",
    "#     'JKO',\n",
    "#     'JKQ',\n",
    "#     'JKS',\n",
    "#     'JKV',\n",
    "#     'JX',\n",
    "#     'MAG',\n",
    "#     'MAJ',\n",
    "#     'MM',\n",
    "#     'NA',\n",
    "#     'NNB',\n",
    "#     'NNBC',\n",
    "#     'NNG',\n",
    "#     'NNP',\n",
    "#     'NP',\n",
    "#     'NR',\n",
    "#     'SC',\n",
    "#     'SF',\n",
    "#     'SL',\n",
    "#     'SN',\n",
    "#     'SSC',\n",
    "#     'SSO',\n",
    "#     'SY',\n",
    "#     'UNA',\n",
    "#     'UNKNOWN',\n",
    "#     'VA',\n",
    "#     'VCN',\n",
    "#     'VCP',\n",
    "#     'VV',\n",
    "#     'VX',\n",
    "#     'XPN',\n",
    "#     'XR',\n",
    "#     'XSA',\n",
    "#     'XSN',\n",
    "#     'XSV',\n",
    "# ]\n",
    "# df_fea[pos_cols] = df_fea.apply(pos, axis=1, result_type='expand')\n",
    "# df_fea[pos_cols] = df_fea[pos_cols].astype(np.int16)\n",
    "# df_fea.rename(columns={c:'fea__'+c for c in pos_cols}, inplace=True)\n",
    "# df_fea.to_pickle('data/df_fea_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T20:58:44.788486Z",
     "start_time": "2020-01-05T20:58:37.292536Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_month</th>\n",
       "      <th>text</th>\n",
       "      <th>smishing</th>\n",
       "      <th>morphs</th>\n",
       "      <th>morphs_str</th>\n",
       "      <th>nouns</th>\n",
       "      <th>nouns_str</th>\n",
       "      <th>fea__EC</th>\n",
       "      <th>fea__EF</th>\n",
       "      <th>fea__EP</th>\n",
       "      <th>...</th>\n",
       "      <th>fea__VA</th>\n",
       "      <th>fea__VCN</th>\n",
       "      <th>fea__VCP</th>\n",
       "      <th>fea__VV</th>\n",
       "      <th>fea__VX</th>\n",
       "      <th>fea__XPN</th>\n",
       "      <th>fea__XR</th>\n",
       "      <th>fea__XSA</th>\n",
       "      <th>fea__XSN</th>\n",
       "      <th>fea__XSV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>XXX은행성산XXX팀장입니다.행복한주말되세요</td>\n",
       "      <td>0</td>\n",
       "      <td>[XXX, 은, 행성, 산, XXX, 팀장, 입니다, ., 행복, 한, 주말, 되,...</td>\n",
       "      <td>XXX 은 행성 산 XXX 팀장 입니다 . 행복 한 주말 되 세요</td>\n",
       "      <td>[행성, 산, 팀장, 행복, 주말]</td>\n",
       "      <td>행성 산 팀장 행복 주말</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>오늘도많이웃으시는하루시작하세요XXX은행 진월동VIP라운지 XXX올림</td>\n",
       "      <td>0</td>\n",
       "      <td>[오늘, 도, 많이, 웃, 으시, 는, 하루, 시작, 하, 세요, XXX, 은행, ...</td>\n",
       "      <td>오늘 도 많이 웃 으시 는 하루 시작 하 세요 XXX 은행 진월동 VIP 라운지 X...</td>\n",
       "      <td>[오늘, 하루, 시작, 은행, 진월동, 라운지]</td>\n",
       "      <td>오늘 하루 시작 은행 진월동 라운지</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>안녕하십니까 고객님. XXX은행입니다.금일 납부하셔야 할 금액은 153600원 입니...</td>\n",
       "      <td>0</td>\n",
       "      <td>[안녕, 하, 십니까, 고객, 님, ., XXX, 은행, 입니다, ., 금일, 납부...</td>\n",
       "      <td>안녕 하 십니까 고객 님 . XXX 은행 입니다 . 금일 납부 하 셔야 할 금액 은...</td>\n",
       "      <td>[안녕, 고객, 은행, 금일, 납부, 금액, 원, 감사, 새해, 복, 은행, 옥포]</td>\n",
       "      <td>안녕 고객 은행 금일 납부 금액 원 감사 새해 복 은행 옥포</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>XXX 고객님안녕하세요XXX은행 XXX지점입니다지난 한 해 동안 저희 XXX지점에 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[XXX, 고객, 님, 안녕, 하, 세요, XXX, 은행, XXX, 지점, 입니다,...</td>\n",
       "      <td>XXX 고객 님 안녕 하 세요 XXX 은행 XXX 지점 입니다 지난 한 해 동안 저...</td>\n",
       "      <td>[고객, 안녕, 은행, 지점, 해, 동안, 저희, 지점, 성원, 감사, 시작, 년,...</td>\n",
       "      <td>고객 안녕 은행 지점 해 동안 저희 지점 성원 감사 시작 년 소망 일 고객 가정 건...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>1월은 새로움이 가득XXX입니다.올 한해 더 많이행복한 한해되시길바랍니다</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 월, 은, 새로움, 이, 가득, XXX, 입니다, ., 올, 한, 해, 더,...</td>\n",
       "      <td>1 월 은 새로움 이 가득 XXX 입니다 . 올 한 해 더 많이 행복 한 한 해 되...</td>\n",
       "      <td>[월, 한, 행복, 해]</td>\n",
       "      <td>월 한 행복 해</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>행복한주말보내세요XXX용현남전담직원대리 XXX올림</td>\n",
       "      <td>0</td>\n",
       "      <td>[행복, 한, 주말, 보내, 세요, XXX, 용, 현남, 전담, 직원, 대리, XX...</td>\n",
       "      <td>행복 한 주말 보내 세요 XXX 용 현남 전담 직원 대리 XXX 올림</td>\n",
       "      <td>[행복, 주말, 현남, 전담, 직원, 대리]</td>\n",
       "      <td>행복 주말 현남 전담 직원 대리</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>XXX 고객님 안녕하세요XXX은행 무교지점 XXX과장입니다 오늘 아침에 눈을 뜨니 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[XXX, 고객, 님, 안녕, 하, 세요, XXX, 은행, 무교, 지점, XXX, ...</td>\n",
       "      <td>XXX 고객 님 안녕 하 세요 XXX 은행 무교 지점 XXX 과장 입니다 오늘 아침...</td>\n",
       "      <td>[고객, 안녕, 은행, 무교, 지점, 과장, 아침, 눈, 눈, 세상, 적, 눈, 눈...</td>\n",
       "      <td>고객 안녕 은행 무교 지점 과장 아침 눈 눈 세상 적 눈 눈 순간 출근 걱정 어른 ...</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>XXX 고객님지난 한해 베풀어 주신 은혜 진심으로 감사 드립니다.가슴 깊이 간직 하...</td>\n",
       "      <td>0</td>\n",
       "      <td>[XXX, 고객, 님, 지난, 한, 해, 베풀, 어, 주, 신, 은혜, 진심, 으로...</td>\n",
       "      <td>XXX 고객 님 지난 한 해 베풀 어 주 신 은혜 진심 으로 감사 드립니다 . 가슴...</td>\n",
       "      <td>[고객, 한, 은혜, 진심, 감사, 가슴, 간직, 정유, 년, 새해, 가족, 행복,...</td>\n",
       "      <td>고객 한 은혜 진심 감사 가슴 간직 정유 년 새해 가족 행복 뜻 바 진심 소망 은행...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>설연휴 가족들과 훈훈한 정 나누시고 정겨운추억 많이 만드세요XXX오XXX올림</td>\n",
       "      <td>0</td>\n",
       "      <td>[설, 연휴, 가족, 들, 과, 훈훈, 한, 정, 나누, 시, 고, 정겨운, 추억,...</td>\n",
       "      <td>설 연휴 가족 들 과 훈훈 한 정 나누 시 고 정겨운 추억 많이 만드세요 XXX 오...</td>\n",
       "      <td>[설, 연휴, 가족, 정, 추억, 오]</td>\n",
       "      <td>설 연휴 가족 정 추억 오</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>(광고)XXXBaXXX고객님들 뒤엔XXX 언제나 XXX새로운 마음가짐으로 새롭게 준...</td>\n",
       "      <td>1</td>\n",
       "      <td>[(, 광고, ), XXXBaXXX, 고객, 님, 들, 뒤, 엔, XXX, 언제나,...</td>\n",
       "      <td>( 광고 ) XXXBaXXX 고객 님 들 뒤 엔 XXX 언제나 XXX 새로운 마음가...</td>\n",
       "      <td>[광고, 고객, 뒤, 마음가짐, 준비, 당, 행상, 품, 자격, 기준, 심사, 기준...</td>\n",
       "      <td>광고 고객 뒤 마음가짐 준비 당 행상 품 자격 기준 심사 기준 완화 상품 상품 정보...</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year_month                                               text  smishing  \\\n",
       "id                                                                           \n",
       "0     2017-01                           XXX은행성산XXX팀장입니다.행복한주말되세요         0   \n",
       "1     2017-01              오늘도많이웃으시는하루시작하세요XXX은행 진월동VIP라운지 XXX올림         0   \n",
       "2     2017-01  안녕하십니까 고객님. XXX은행입니다.금일 납부하셔야 할 금액은 153600원 입니...         0   \n",
       "4     2017-01  XXX 고객님안녕하세요XXX은행 XXX지점입니다지난 한 해 동안 저희 XXX지점에 ...         0   \n",
       "5     2017-01           1월은 새로움이 가득XXX입니다.올 한해 더 많이행복한 한해되시길바랍니다         0   \n",
       "6     2017-01                        행복한주말보내세요XXX용현남전담직원대리 XXX올림         0   \n",
       "7     2017-01  XXX 고객님 안녕하세요XXX은행 무교지점 XXX과장입니다 오늘 아침에 눈을 뜨니 ...         0   \n",
       "8     2017-01  XXX 고객님지난 한해 베풀어 주신 은혜 진심으로 감사 드립니다.가슴 깊이 간직 하...         0   \n",
       "9     2017-01         설연휴 가족들과 훈훈한 정 나누시고 정겨운추억 많이 만드세요XXX오XXX올림         0   \n",
       "10    2017-01  (광고)XXXBaXXX고객님들 뒤엔XXX 언제나 XXX새로운 마음가짐으로 새롭게 준...         1   \n",
       "\n",
       "                                               morphs  \\\n",
       "id                                                      \n",
       "0   [XXX, 은, 행성, 산, XXX, 팀장, 입니다, ., 행복, 한, 주말, 되,...   \n",
       "1   [오늘, 도, 많이, 웃, 으시, 는, 하루, 시작, 하, 세요, XXX, 은행, ...   \n",
       "2   [안녕, 하, 십니까, 고객, 님, ., XXX, 은행, 입니다, ., 금일, 납부...   \n",
       "4   [XXX, 고객, 님, 안녕, 하, 세요, XXX, 은행, XXX, 지점, 입니다,...   \n",
       "5   [1, 월, 은, 새로움, 이, 가득, XXX, 입니다, ., 올, 한, 해, 더,...   \n",
       "6   [행복, 한, 주말, 보내, 세요, XXX, 용, 현남, 전담, 직원, 대리, XX...   \n",
       "7   [XXX, 고객, 님, 안녕, 하, 세요, XXX, 은행, 무교, 지점, XXX, ...   \n",
       "8   [XXX, 고객, 님, 지난, 한, 해, 베풀, 어, 주, 신, 은혜, 진심, 으로...   \n",
       "9   [설, 연휴, 가족, 들, 과, 훈훈, 한, 정, 나누, 시, 고, 정겨운, 추억,...   \n",
       "10  [(, 광고, ), XXXBaXXX, 고객, 님, 들, 뒤, 엔, XXX, 언제나,...   \n",
       "\n",
       "                                           morphs_str  \\\n",
       "id                                                      \n",
       "0                XXX 은 행성 산 XXX 팀장 입니다 . 행복 한 주말 되 세요   \n",
       "1   오늘 도 많이 웃 으시 는 하루 시작 하 세요 XXX 은행 진월동 VIP 라운지 X...   \n",
       "2   안녕 하 십니까 고객 님 . XXX 은행 입니다 . 금일 납부 하 셔야 할 금액 은...   \n",
       "4   XXX 고객 님 안녕 하 세요 XXX 은행 XXX 지점 입니다 지난 한 해 동안 저...   \n",
       "5   1 월 은 새로움 이 가득 XXX 입니다 . 올 한 해 더 많이 행복 한 한 해 되...   \n",
       "6              행복 한 주말 보내 세요 XXX 용 현남 전담 직원 대리 XXX 올림   \n",
       "7   XXX 고객 님 안녕 하 세요 XXX 은행 무교 지점 XXX 과장 입니다 오늘 아침...   \n",
       "8   XXX 고객 님 지난 한 해 베풀 어 주 신 은혜 진심 으로 감사 드립니다 . 가슴...   \n",
       "9   설 연휴 가족 들 과 훈훈 한 정 나누 시 고 정겨운 추억 많이 만드세요 XXX 오...   \n",
       "10  ( 광고 ) XXXBaXXX 고객 님 들 뒤 엔 XXX 언제나 XXX 새로운 마음가...   \n",
       "\n",
       "                                                nouns  \\\n",
       "id                                                      \n",
       "0                                 [행성, 산, 팀장, 행복, 주말]   \n",
       "1                          [오늘, 하루, 시작, 은행, 진월동, 라운지]   \n",
       "2      [안녕, 고객, 은행, 금일, 납부, 금액, 원, 감사, 새해, 복, 은행, 옥포]   \n",
       "4   [고객, 안녕, 은행, 지점, 해, 동안, 저희, 지점, 성원, 감사, 시작, 년,...   \n",
       "5                                       [월, 한, 행복, 해]   \n",
       "6                            [행복, 주말, 현남, 전담, 직원, 대리]   \n",
       "7   [고객, 안녕, 은행, 무교, 지점, 과장, 아침, 눈, 눈, 세상, 적, 눈, 눈...   \n",
       "8   [고객, 한, 은혜, 진심, 감사, 가슴, 간직, 정유, 년, 새해, 가족, 행복,...   \n",
       "9                               [설, 연휴, 가족, 정, 추억, 오]   \n",
       "10  [광고, 고객, 뒤, 마음가짐, 준비, 당, 행상, 품, 자격, 기준, 심사, 기준...   \n",
       "\n",
       "                                            nouns_str  fea__EC  fea__EF  \\\n",
       "id                                                                        \n",
       "0                                       행성 산 팀장 행복 주말        0        2   \n",
       "1                                 오늘 하루 시작 은행 진월동 라운지        1        1   \n",
       "2                   안녕 고객 은행 금일 납부 금액 원 감사 새해 복 은행 옥포        2        5   \n",
       "4   고객 안녕 은행 지점 해 동안 저희 지점 성원 감사 시작 년 소망 일 고객 가정 건...        1        5   \n",
       "5                                            월 한 행복 해        2        1   \n",
       "6                                   행복 주말 현남 전담 직원 대리        1        1   \n",
       "7   고객 안녕 은행 무교 지점 과장 아침 눈 눈 세상 적 눈 눈 순간 출근 걱정 어른 ...       15        8   \n",
       "8   고객 한 은혜 진심 감사 가슴 간직 정유 년 새해 가족 행복 뜻 바 진심 소망 은행...        3        3   \n",
       "9                                      설 연휴 가족 정 추억 오        3        0   \n",
       "10  광고 고객 뒤 마음가짐 준비 당 행상 품 자격 기준 심사 기준 완화 상품 상품 정보...       29        7   \n",
       "\n",
       "    fea__EP  ...  fea__VA  fea__VCN  fea__VCP  fea__VV  fea__VX  fea__XPN  \\\n",
       "id           ...                                                            \n",
       "0         1  ...        0         0         1        0        0         0   \n",
       "1         2  ...        0         0         0        2        0         0   \n",
       "2         4  ...        0         0         2        2        1         0   \n",
       "4         5  ...        0         0         1        7        1         0   \n",
       "5         1  ...        1         0         1        1        0         0   \n",
       "6         1  ...        0         0         0        2        0         0   \n",
       "7        10  ...        5         0         2       22        2         0   \n",
       "8         4  ...        0         0         0        5        1         0   \n",
       "9         2  ...        1         0         0        3        0         0   \n",
       "10       15  ...       10         0         4       18        6         1   \n",
       "\n",
       "    fea__XR  fea__XSA  fea__XSN  fea__XSV  \n",
       "id                                         \n",
       "0         0         1         0         1  \n",
       "1         0         0         0         1  \n",
       "2         0         0         1         3  \n",
       "4         0         2         2         4  \n",
       "5         0         1         0         2  \n",
       "6         0         1         1         0  \n",
       "7         2         2         2         4  \n",
       "8         0         2         1         2  \n",
       "9         1         1         1         0  \n",
       "10        2         8        12         5  \n",
       "\n",
       "[10 rows x 51 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fea = pd.read_pickle('data/df_fea_1.pkl')\n",
    "df_fea.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T20:58:44.791761Z",
     "start_time": "2020-01-05T20:58:44.789322Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year_month', 'text', 'smishing', 'morphs', 'morphs_str', 'nouns',\n",
       "       'nouns_str', 'fea__EC', 'fea__EF', 'fea__EP', 'fea__ETM', 'fea__ETN',\n",
       "       'fea__IC', 'fea__JC', 'fea__JKB', 'fea__JKC', 'fea__JKG', 'fea__JKO',\n",
       "       'fea__JKQ', 'fea__JKS', 'fea__JKV', 'fea__JX', 'fea__MAG', 'fea__MAJ',\n",
       "       'fea__MM', 'fea__NA', 'fea__NNB', 'fea__NNBC', 'fea__NNG', 'fea__NNP',\n",
       "       'fea__NP', 'fea__NR', 'fea__SC', 'fea__SF', 'fea__SL', 'fea__SN',\n",
       "       'fea__SSC', 'fea__SSO', 'fea__SY', 'fea__UNA', 'fea__UNKNOWN',\n",
       "       'fea__VA', 'fea__VCN', 'fea__VCP', 'fea__VV', 'fea__VX', 'fea__XPN',\n",
       "       'fea__XR', 'fea__XSA', 'fea__XSN', 'fea__XSV'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fea.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T20:58:44.805416Z",
     "start_time": "2020-01-05T20:58:44.792524Z"
    }
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "fea_dict = {}\n",
    "\n",
    "vocab = None\n",
    "stop_words = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq Fea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAX_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T20:58:44.818730Z",
     "start_time": "2020-01-05T20:58:44.806560Z"
    }
   },
   "outputs": [],
   "source": [
    "def toidx(src_col, max_len, reverse=False):\n",
    "    idx_col_nm = '{}_{}_idx'.format(src_col, max_len)\n",
    "    if reverse:\n",
    "        idx_col_nm = idx_col_nm.replace('idx', 'ridx')\n",
    "\n",
    "    vocab_set = set()\n",
    "    _ = df_fea[src_col].apply(lambda x: [vocab_set.add(c) for c in x])\n",
    "    \n",
    "    vocab_dict = {v: i+1 for i, v in enumerate(vocab_set)}\n",
    "    vocab_dim = len(vocab_dict.keys()) + 1\n",
    "\n",
    "    def _toidx(x):\n",
    "        if reverse:\n",
    "            x = x[::-1]\n",
    "        return [int(vocab_dict[x[i]]) if i < len(x) else 0 for i in range(max_len)]\n",
    "\n",
    "#     print(vocab_dim, max_len)\n",
    "    \n",
    "    return idx_col_nm, df_fea[src_col].apply(_toidx), vocab_dim, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T20:58:44.837198Z",
     "start_time": "2020-01-05T20:58:44.821025Z"
    }
   },
   "outputs": [],
   "source": [
    "src_col = 'morphs'\n",
    "# src_col = 'text'\n",
    "max_len = 128#512#256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T20:58:44.851208Z",
     "start_time": "2020-01-05T20:58:44.838845Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# vectorizer = CountVectorizer(max_features=1000)\n",
    "# vectorizer = vectorizer.fit(df_fea['morphs_str'].values)\n",
    "\n",
    "# seq_vocab = set(vectorizer.get_feature_names())\n",
    "\n",
    "# org_max_len = df_fea[src_col].str.len().max()\n",
    "# df_fea[src_col] = df_fea[src_col].apply(lambda x: [m for m in x if m in seq_vocab])\n",
    "# max_len = df_fea[src_col].str.len().max()\n",
    "# print(org_max_len, 'to', max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T20:58:53.740019Z",
     "start_time": "2020-01-05T20:58:44.852474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('morphs_128_idx', 49980, 128)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c, d, vocab_dim, max_len = toidx(src_col, max_len)\n",
    "df_fea[c] = d\n",
    "c, vocab_dim, max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T20:59:03.091674Z",
     "start_time": "2020-01-05T20:58:53.741048Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('morphs_128_ridx', 49980, 128)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c, d, vocab_dim, max_len = toidx(src_col, max_len, reverse=True)\n",
    "df_fea[c] = d\n",
    "c, vocab_dim, max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T20:59:03.712471Z",
     "start_time": "2020-01-05T20:59:03.092618Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_month</th>\n",
       "      <th>text</th>\n",
       "      <th>smishing</th>\n",
       "      <th>morphs</th>\n",
       "      <th>morphs_str</th>\n",
       "      <th>nouns</th>\n",
       "      <th>nouns_str</th>\n",
       "      <th>fea__EC</th>\n",
       "      <th>fea__EF</th>\n",
       "      <th>fea__EP</th>\n",
       "      <th>...</th>\n",
       "      <th>rate_fea__XSA_textlen</th>\n",
       "      <th>rate_fea__XSA_morphcnt</th>\n",
       "      <th>rate_fea__XSN_textlen</th>\n",
       "      <th>rate_fea__XSN_morphcnt</th>\n",
       "      <th>rate_fea__XSV_textlen</th>\n",
       "      <th>rate_fea__XSV_morphcnt</th>\n",
       "      <th>rate_fea__text_len_textlen</th>\n",
       "      <th>rate_fea__text_len_morphcnt</th>\n",
       "      <th>rate_fea__morphs_cnt_textlen</th>\n",
       "      <th>rate_fea__morphs_cnt_morphcnt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>XXX은행성산XXX팀장입니다.행복한주말되세요</td>\n",
       "      <td>0</td>\n",
       "      <td>[XXX, 은, 행성, 산, XXX, 팀장, 입니다, ., 행복, 한, 주말, 되,...</td>\n",
       "      <td>XXX 은 행성 산 XXX 팀장 입니다 . 행복 한 주말 되 세요</td>\n",
       "      <td>[행성, 산, 팀장, 행복, 주말]</td>\n",
       "      <td>행성 산 팀장 행복 주말</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.845703</td>\n",
       "      <td>0.541504</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>오늘도많이웃으시는하루시작하세요XXX은행 진월동VIP라운지 XXX올림</td>\n",
       "      <td>0</td>\n",
       "      <td>[오늘, 도, 많이, 웃, 으시, 는, 하루, 시작, 하, 세요, XXX, 은행, ...</td>\n",
       "      <td>오늘 도 많이 웃 으시 는 하루 시작 하 세요 XXX 은행 진월동 VIP 라운지 X...</td>\n",
       "      <td>[오늘, 하루, 시작, 은행, 진월동, 라운지]</td>\n",
       "      <td>오늘 하루 시작 은행 진월동 라운지</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.175781</td>\n",
       "      <td>0.459473</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>안녕하십니까 고객님. XXX은행입니다.금일 납부하셔야 할 금액은 153600원 입니...</td>\n",
       "      <td>0</td>\n",
       "      <td>[안녕, 하, 십니까, 고객, 님, ., XXX, 은행, 입니다, ., 금일, 납부...</td>\n",
       "      <td>안녕 하 십니까 고객 님 . XXX 은행 입니다 . 금일 납부 하 셔야 할 금액 은...</td>\n",
       "      <td>[안녕, 고객, 은행, 금일, 납부, 금액, 원, 감사, 새해, 복, 은행, 옥포]</td>\n",
       "      <td>안녕 고객 은행 금일 납부 금액 원 감사 새해 복 은행 옥포</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.314453</td>\n",
       "      <td>0.432129</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>XXX 고객님안녕하세요XXX은행 XXX지점입니다지난 한 해 동안 저희 XXX지점에 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[XXX, 고객, 님, 안녕, 하, 세요, XXX, 은행, XXX, 지점, 입니다,...</td>\n",
       "      <td>XXX 고객 님 안녕 하 세요 XXX 은행 XXX 지점 입니다 지난 한 해 동안 저...</td>\n",
       "      <td>[고객, 안녕, 은행, 지점, 해, 동안, 저희, 지점, 성원, 감사, 시작, 년,...</td>\n",
       "      <td>고객 안녕 은행 지점 해 동안 저희 지점 성원 감사 시작 년 소망 일 고객 가정 건...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.148438</td>\n",
       "      <td>0.465576</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>1월은 새로움이 가득XXX입니다.올 한해 더 많이행복한 한해되시길바랍니다</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 월, 은, 새로움, 이, 가득, XXX, 입니다, ., 올, 한, 해, 더,...</td>\n",
       "      <td>1 월 은 새로움 이 가득 XXX 입니다 . 올 한 해 더 많이 행복 한 한 해 되...</td>\n",
       "      <td>[월, 한, 행복, 해]</td>\n",
       "      <td>월 한 행복 해</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.818359</td>\n",
       "      <td>0.549805</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>341621</td>\n",
       "      <td>2019-04</td>\n",
       "      <td>(광고)XXX 고객님안녕하십니까!!고객님의 소중한 업무처리를 도와드린 kb창원중앙동...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[(, 광고, ), XXX, 고객, 님, 안녕, 하, 십니까, !, !, 고객, 님...</td>\n",
       "      <td>( 광고 ) XXX 고객 님 안녕 하 십니까 ! ! 고객 님 의 소중 한 업무 처리...</td>\n",
       "      <td>[광고, 고객, 안녕, 고객, 업무, 처리, 창원, 중앙동, 지점, 계장, 업무, ...</td>\n",
       "      <td>광고 고객 안녕 고객 업무 처리 창원 중앙동 지점 계장 업무 처리 불편 아침 봄비 ...</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010239</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>0.010239</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>0.006826</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.107422</td>\n",
       "      <td>0.474365</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>341622</td>\n",
       "      <td>2019-04</td>\n",
       "      <td>고객님 항상 저희 지점을 거래해 주셔서 감사합니다  본점 서비스 설문 전화 받으시면...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[고객, 님, 항상, 저희, 지점, 을, 거래, 해, 주, 셔서, 감사, 합니다, ...</td>\n",
       "      <td>고객 님 항상 저희 지점 을 거래 해 주 셔서 감사 합니다 본점 서비스 설문 전화 ...</td>\n",
       "      <td>[고객, 저희, 지점, 거래, 감사, 본점, 서비스, 설문, 전화, 동의, 부탁, ...</td>\n",
       "      <td>고객 저희 지점 거래 감사 본점 서비스 설문 전화 동의 부탁 오늘 하루 은행 호평</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.529297</td>\n",
       "      <td>0.395264</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>341623</td>\n",
       "      <td>2019-04</td>\n",
       "      <td>XXX 고객님 저희 XXX은행 XXX지점을 이용해주셔서 감사드립니다  이번주도 더 ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[XXX, 고객, 님, 저희, XXX, 은행, XXX, 지점, 을, 이용, 해, 주...</td>\n",
       "      <td>XXX 고객 님 저희 XXX 은행 XXX 지점 을 이용 해 주 셔서 감사 드립니다 ...</td>\n",
       "      <td>[고객, 저희, 은행, 지점, 이용, 감사, 이번, 주도, 행복, 시간, 기원, 은...</td>\n",
       "      <td>고객 저희 은행 지점 이용 감사 이번 주도 행복 시간 기원 은행 화정</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.199219</td>\n",
       "      <td>0.454590</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>341624</td>\n",
       "      <td>2019-04</td>\n",
       "      <td>(광고)알림 신청하면 매일 현금 100만원! XXX부동산 리브온지금 XXX부동산 리...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[(, 광고, ), 알림, 신청, 하, 면, 매일, 현금, 100, 만, 원, !,...</td>\n",
       "      <td>( 광고 ) 알림 신청 하 면 매일 현금 100 만 원 ! XXX 부동산 리브 온 ...</td>\n",
       "      <td>[광고, 신청, 현금, 만, 원, 부동산, 리브, 지금, 부동산, 리브, 신청, 만...</td>\n",
       "      <td>광고 신청 현금 만 원 부동산 리브 지금 부동산 리브 신청 만 원 행운 매물 시세 ...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>0.006390</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0.008759</td>\n",
       "      <td>0.019169</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.189453</td>\n",
       "      <td>0.457031</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>341625</td>\n",
       "      <td>2019-04</td>\n",
       "      <td>(광고) XXX 고객님 안녕하세요.XXX봉XXX점 XXX대리입니다. 군인연금수급권자...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[(, 광고, ), XXX, 고객, 님, 안녕, 하, 세요, ., XXX, 봉, X...</td>\n",
       "      <td>( 광고 ) XXX 고객 님 안녕 하 세요 . XXX 봉 XXX 점 XXX 대리 입...</td>\n",
       "      <td>[광고, 고객, 안녕, 봉, 점, 대리, 군인, 연금, 수급, 대출, 상품, 출시,...</td>\n",
       "      <td>광고 고객 안녕 봉 점 대리 군인 연금 수급 대출 상품 출시 안내 군인 연금 수급 ...</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.017578</td>\n",
       "      <td>0.495850</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297571 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year_month                                               text  \\\n",
       "id                                                                     \n",
       "0         2017-01                           XXX은행성산XXX팀장입니다.행복한주말되세요   \n",
       "1         2017-01              오늘도많이웃으시는하루시작하세요XXX은행 진월동VIP라운지 XXX올림   \n",
       "2         2017-01  안녕하십니까 고객님. XXX은행입니다.금일 납부하셔야 할 금액은 153600원 입니...   \n",
       "4         2017-01  XXX 고객님안녕하세요XXX은행 XXX지점입니다지난 한 해 동안 저희 XXX지점에 ...   \n",
       "5         2017-01           1월은 새로움이 가득XXX입니다.올 한해 더 많이행복한 한해되시길바랍니다   \n",
       "...           ...                                                ...   \n",
       "341621    2019-04  (광고)XXX 고객님안녕하십니까!!고객님의 소중한 업무처리를 도와드린 kb창원중앙동...   \n",
       "341622    2019-04  고객님 항상 저희 지점을 거래해 주셔서 감사합니다  본점 서비스 설문 전화 받으시면...   \n",
       "341623    2019-04  XXX 고객님 저희 XXX은행 XXX지점을 이용해주셔서 감사드립니다  이번주도 더 ...   \n",
       "341624    2019-04  (광고)알림 신청하면 매일 현금 100만원! XXX부동산 리브온지금 XXX부동산 리...   \n",
       "341625    2019-04  (광고) XXX 고객님 안녕하세요.XXX봉XXX점 XXX대리입니다. 군인연금수급권자...   \n",
       "\n",
       "        smishing                                             morphs  \\\n",
       "id                                                                    \n",
       "0              0  [XXX, 은, 행성, 산, XXX, 팀장, 입니다, ., 행복, 한, 주말, 되,...   \n",
       "1              0  [오늘, 도, 많이, 웃, 으시, 는, 하루, 시작, 하, 세요, XXX, 은행, ...   \n",
       "2              0  [안녕, 하, 십니까, 고객, 님, ., XXX, 은행, 입니다, ., 금일, 납부...   \n",
       "4              0  [XXX, 고객, 님, 안녕, 하, 세요, XXX, 은행, XXX, 지점, 입니다,...   \n",
       "5              0  [1, 월, 은, 새로움, 이, 가득, XXX, 입니다, ., 올, 한, 해, 더,...   \n",
       "...          ...                                                ...   \n",
       "341621        -1  [(, 광고, ), XXX, 고객, 님, 안녕, 하, 십니까, !, !, 고객, 님...   \n",
       "341622        -1  [고객, 님, 항상, 저희, 지점, 을, 거래, 해, 주, 셔서, 감사, 합니다, ...   \n",
       "341623        -1  [XXX, 고객, 님, 저희, XXX, 은행, XXX, 지점, 을, 이용, 해, 주...   \n",
       "341624        -1  [(, 광고, ), 알림, 신청, 하, 면, 매일, 현금, 100, 만, 원, !,...   \n",
       "341625        -1  [(, 광고, ), XXX, 고객, 님, 안녕, 하, 세요, ., XXX, 봉, X...   \n",
       "\n",
       "                                               morphs_str  \\\n",
       "id                                                          \n",
       "0                    XXX 은 행성 산 XXX 팀장 입니다 . 행복 한 주말 되 세요   \n",
       "1       오늘 도 많이 웃 으시 는 하루 시작 하 세요 XXX 은행 진월동 VIP 라운지 X...   \n",
       "2       안녕 하 십니까 고객 님 . XXX 은행 입니다 . 금일 납부 하 셔야 할 금액 은...   \n",
       "4       XXX 고객 님 안녕 하 세요 XXX 은행 XXX 지점 입니다 지난 한 해 동안 저...   \n",
       "5       1 월 은 새로움 이 가득 XXX 입니다 . 올 한 해 더 많이 행복 한 한 해 되...   \n",
       "...                                                   ...   \n",
       "341621  ( 광고 ) XXX 고객 님 안녕 하 십니까 ! ! 고객 님 의 소중 한 업무 처리...   \n",
       "341622  고객 님 항상 저희 지점 을 거래 해 주 셔서 감사 합니다 본점 서비스 설문 전화 ...   \n",
       "341623  XXX 고객 님 저희 XXX 은행 XXX 지점 을 이용 해 주 셔서 감사 드립니다 ...   \n",
       "341624  ( 광고 ) 알림 신청 하 면 매일 현금 100 만 원 ! XXX 부동산 리브 온 ...   \n",
       "341625  ( 광고 ) XXX 고객 님 안녕 하 세요 . XXX 봉 XXX 점 XXX 대리 입...   \n",
       "\n",
       "                                                    nouns  \\\n",
       "id                                                          \n",
       "0                                     [행성, 산, 팀장, 행복, 주말]   \n",
       "1                              [오늘, 하루, 시작, 은행, 진월동, 라운지]   \n",
       "2          [안녕, 고객, 은행, 금일, 납부, 금액, 원, 감사, 새해, 복, 은행, 옥포]   \n",
       "4       [고객, 안녕, 은행, 지점, 해, 동안, 저희, 지점, 성원, 감사, 시작, 년,...   \n",
       "5                                           [월, 한, 행복, 해]   \n",
       "...                                                   ...   \n",
       "341621  [광고, 고객, 안녕, 고객, 업무, 처리, 창원, 중앙동, 지점, 계장, 업무, ...   \n",
       "341622  [고객, 저희, 지점, 거래, 감사, 본점, 서비스, 설문, 전화, 동의, 부탁, ...   \n",
       "341623  [고객, 저희, 은행, 지점, 이용, 감사, 이번, 주도, 행복, 시간, 기원, 은...   \n",
       "341624  [광고, 신청, 현금, 만, 원, 부동산, 리브, 지금, 부동산, 리브, 신청, 만...   \n",
       "341625  [광고, 고객, 안녕, 봉, 점, 대리, 군인, 연금, 수급, 대출, 상품, 출시,...   \n",
       "\n",
       "                                                nouns_str  fea__EC  fea__EF  \\\n",
       "id                                                                            \n",
       "0                                           행성 산 팀장 행복 주말        0        2   \n",
       "1                                     오늘 하루 시작 은행 진월동 라운지        1        1   \n",
       "2                       안녕 고객 은행 금일 납부 금액 원 감사 새해 복 은행 옥포        2        5   \n",
       "4       고객 안녕 은행 지점 해 동안 저희 지점 성원 감사 시작 년 소망 일 고객 가정 건...        1        5   \n",
       "5                                                월 한 행복 해        2        1   \n",
       "...                                                   ...      ...      ...   \n",
       "341621  광고 고객 안녕 고객 업무 처리 창원 중앙동 지점 계장 업무 처리 불편 아침 봄비 ...        7        8   \n",
       "341622      고객 저희 지점 거래 감사 본점 서비스 설문 전화 동의 부탁 오늘 하루 은행 호평        5        2   \n",
       "341623             고객 저희 은행 지점 이용 감사 이번 주도 행복 시간 기원 은행 화정        5        1   \n",
       "341624  광고 신청 현금 만 원 부동산 리브 지금 부동산 리브 신청 만 원 행운 매물 시세 ...        9        3   \n",
       "341625  광고 고객 안녕 봉 점 대리 군인 연금 수급 대출 상품 출시 안내 군인 연금 수급 ...        7        8   \n",
       "\n",
       "        fea__EP  ...  rate_fea__XSA_textlen  rate_fea__XSA_morphcnt  \\\n",
       "id               ...                                                  \n",
       "0             1  ...               0.041667                0.076923   \n",
       "1             2  ...               0.000000                0.000000   \n",
       "2             4  ...               0.000000                0.000000   \n",
       "4             5  ...               0.011494                0.024691   \n",
       "5             1  ...               0.025000                0.045455   \n",
       "...         ...  ...                    ...                     ...   \n",
       "341621        8  ...               0.010239                0.021583   \n",
       "341622        3  ...               0.000000                0.000000   \n",
       "341623        2  ...               0.011364                0.025000   \n",
       "341624        3  ...               0.002920                0.006390   \n",
       "341625        2  ...               0.008264                0.016667   \n",
       "\n",
       "        rate_fea__XSN_textlen  rate_fea__XSN_morphcnt  rate_fea__XSV_textlen  \\\n",
       "id                                                                             \n",
       "0                    0.000000                0.000000               0.041667   \n",
       "1                    0.000000                0.000000               0.027027   \n",
       "2                    0.012346                0.028571               0.037037   \n",
       "4                    0.011494                0.024691               0.022989   \n",
       "5                    0.000000                0.000000               0.050000   \n",
       "...                       ...                     ...                    ...   \n",
       "341621               0.010239                0.021583               0.006826   \n",
       "341622               0.011628                0.029412               0.023256   \n",
       "341623               0.022727                0.050000               0.022727   \n",
       "341624               0.001460                0.003195               0.008759   \n",
       "341625               0.024793                0.050000               0.024793   \n",
       "\n",
       "        rate_fea__XSV_morphcnt  rate_fea__text_len_textlen  \\\n",
       "id                                                           \n",
       "0                     0.076923                         1.0   \n",
       "1                     0.058824                         1.0   \n",
       "2                     0.085714                         1.0   \n",
       "4                     0.049383                         1.0   \n",
       "5                     0.090909                         1.0   \n",
       "...                        ...                         ...   \n",
       "341621                0.014388                         1.0   \n",
       "341622                0.058824                         1.0   \n",
       "341623                0.050000                         1.0   \n",
       "341624                0.019169                         1.0   \n",
       "341625                0.050000                         1.0   \n",
       "\n",
       "        rate_fea__text_len_morphcnt  rate_fea__morphs_cnt_textlen  \\\n",
       "id                                                                  \n",
       "0                          1.845703                      0.541504   \n",
       "1                          2.175781                      0.459473   \n",
       "2                          2.314453                      0.432129   \n",
       "4                          2.148438                      0.465576   \n",
       "5                          1.818359                      0.549805   \n",
       "...                             ...                           ...   \n",
       "341621                     2.107422                      0.474365   \n",
       "341622                     2.529297                      0.395264   \n",
       "341623                     2.199219                      0.454590   \n",
       "341624                     2.189453                      0.457031   \n",
       "341625                     2.017578                      0.495850   \n",
       "\n",
       "        rate_fea__morphs_cnt_morphcnt  \n",
       "id                                     \n",
       "0                                 1.0  \n",
       "1                                 1.0  \n",
       "2                                 1.0  \n",
       "4                                 1.0  \n",
       "5                                 1.0  \n",
       "...                               ...  \n",
       "341621                            1.0  \n",
       "341622                            1.0  \n",
       "341623                            1.0  \n",
       "341624                            1.0  \n",
       "341625                            1.0  \n",
       "\n",
       "[297571 rows x 147 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fea['fea__text_len'] = df_fea['text'].str.len().fillna(0).astype(np.float16)\n",
    "df_fea['fea__morphs_cnt'] = df_fea['morphs'].apply(lambda x: len(x)).fillna(0).astype(np.float16)\n",
    "# df_fea['fea__noun_cnt'] = df_fea['nouns'].apply(lambda x: len(x)).fillna(0).astype(np.float16)\n",
    "\n",
    "for c in [c for c in df_fea.columns if 'fea__' in c]:\n",
    "    df_fea[f'rate_{c}_textlen'] = df_fea[c]  /  df_fea['fea__text_len']\n",
    "    df_fea[f'rate_{c}_morphcnt'] = df_fea[c]  /  df_fea['fea__morphs_cnt']\n",
    "    \n",
    "df_fea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T20:46:36.374836Z",
     "start_time": "2020-01-05T20:46:36.372821Z"
    }
   },
   "source": [
    "### Count Diff cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T20:59:19.004757Z",
     "start_time": "2020-01-05T20:59:03.713302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297571, 38)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_cols = ['가능', '상품', '금리', '으로', '등급', '대출', 'XXX', '상담', '습니다', '신용', '한도',\n",
    "       '신청', '까지', '드립니다', '부채', '진행', '통합', '드리', '문자', '은행', '거부', '이상',\n",
    "       '직장', '추가', '전환', '사용', '방식', '합니다', '방법', '광고', '전화', '자격', '수신',\n",
    "       '이자', '에서', '대환', '자금', '거나', '금융']\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(vocabulary=cnt_cols)\n",
    "\n",
    "vectorizer = vectorizer.fit(df_fea['morphs_str'].values)\n",
    "cnt_vec = vectorizer.transform(df_fea['morphs_str'].values).toarray()\n",
    "\n",
    "\n",
    "cnt_dict = {'diff_cnt_{0:04d}'.format(i):'diff_cnt_{0:04}_{1}'.format(i, c) for i, c in enumerate(vectorizer.get_feature_names())}\n",
    "fea_dict.update(cnt_dict)\n",
    "cnt_cols = sorted(cnt_dict.keys())\n",
    "\n",
    "df_cnt_vec = pd.DataFrame(data=cnt_vec, index=df_fea.index, columns=cnt_cols, dtype=np.float16)\n",
    "df_cnt_vec = df_cnt_vec.loc[:, (df_cnt_vec != 0).any(axis=0)]\n",
    "dfs.append(df_cnt_vec)\n",
    "df_cnt_vec.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T20:59:54.110200Z",
     "start_time": "2020-01-05T20:59:19.005548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297571, 999)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='char',\n",
    "#                              vocabulary=vocab,\n",
    "                             stop_words=stop_words, \n",
    "                             max_df=1.0,\n",
    "                             min_df=100)\n",
    "\n",
    "# vectorizer = vectorizer.fit(df_fea[df_fea['smishing']==1]['nouns_str'].values)\n",
    "vectorizer = vectorizer.fit(df_fea['text'].values)\n",
    "cnt_vec = vectorizer.transform(df_fea['text'].values).toarray()\n",
    "\n",
    "cnt_dict = {'cnt_{0:04d}'.format(i):'cnt_{0:04}_{1}'.format(i, c) for i, c in enumerate(vectorizer.get_feature_names())}\n",
    "fea_dict.update(cnt_dict)\n",
    "cnt_cols = sorted(cnt_dict.keys())\n",
    "\n",
    "df_cnt_vec = pd.DataFrame(data=cnt_vec, index=df_fea.index, columns=cnt_cols, dtype=np.float16)\n",
    "df_cnt_vec = df_cnt_vec.loc[:, (df_cnt_vec != 0).any(axis=0)]\n",
    "dfs.append(df_cnt_vec)\n",
    "df_cnt_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T20:59:54.115133Z",
     "start_time": "2020-01-05T20:59:54.111026Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "l2Dgkdt6pZw_"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def tfidf(data, params, tfidf_tag):\n",
    "    vectorizer = TfidfVectorizer(**params)\n",
    "    vectorizer = vectorizer.fit(data)\n",
    "\n",
    "    d = {'{0}_{1:04d}'.format(tfidf_tag, v):'{0}_{1:04d}_{2}'.format(tfidf_tag, v, k) for k, v in sorted(vectorizer.vocabulary_.items(), key=lambda item: item[1])}\n",
    "    c = sorted(d.keys())\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "#         data=vectorizer.transform(df_fea['nouns_str'].values).toarray(),\n",
    "        data=vectorizer.transform(df_fea['morphs_str'].values).toarray(),\n",
    "        columns=c, \n",
    "        index=df_fea.index,\n",
    "        dtype=np.float16)\n",
    "    \n",
    "    # Remove all zeros column\n",
    "    df = df.loc[:, (df != 0).any(axis=0)]\n",
    "    d = {k:v for k, v in d.items() if k in df.columns}\n",
    "    \n",
    "    print(tfidf_tag, df.shape)\n",
    "    \n",
    "    return df, d, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T20:59:54.130078Z",
     "start_time": "2020-01-05T20:59:54.115869Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_src_col = 'morphs_str'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T21:00:34.963071Z",
     "start_time": "2020-01-05T20:59:54.131236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_char_11 (297571, 999)\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'analyzer' : 'char',\n",
    "    'max_features':None, \n",
    "#     'vocabulary': vocab,\n",
    "    'stop_words':stop_words, \n",
    "#     'max_df':0.1, \n",
    "    'min_df':100, \n",
    "    'ngram_range':(1, 1), \n",
    "}\n",
    "df, d, v = tfidf(df_fea[tfidf_src_col].values, params, 'tfidf_char_11')\n",
    "dfs.append(df)\n",
    "fea_dict.update(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T21:01:04.489096Z",
     "start_time": "2020-01-05T21:00:34.963934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_word_11 (297571, 3000)\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_features': 3000,#2500,#2000, \n",
    "#     'vocabulary': vocab,\n",
    "    'stop_words':stop_words, \n",
    "    'max_df':1.0, \n",
    "    'min_df':200, \n",
    "    'ngram_range':(1, 1), \n",
    "}\n",
    "df, d, v = tfidf(df_fea[tfidf_src_col].values, params, 'tfidf_word_11')\n",
    "dfs.append(df)\n",
    "fea_dict.update(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T21:01:42.081212Z",
     "start_time": "2020-01-05T21:01:04.489968Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "l2Dgkdt6pZw_",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_word_22 (297571, 3000)\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_features':3000,#2500,#2000, \n",
    "#     'vocabulary': vocab,\n",
    "    'stop_words':stop_words, \n",
    "    'max_df':1.0, \n",
    "    'min_df':500, \n",
    "    'ngram_range':(2, 2), \n",
    "}\n",
    "df, d, v = tfidf(df_fea[tfidf_src_col].values, params, 'tfidf_word_22')\n",
    "dfs.append(df)\n",
    "fea_dict.update(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T21:02:16.238083Z",
     "start_time": "2020-01-05T21:01:42.082048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_word_33 (297571, 1500)\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_features':1500, #1000,#500, \n",
    "#     'vocabulary': vocab,\n",
    "    'stop_words':stop_words, \n",
    "    'max_df':1.0, \n",
    "    'min_df':500, \n",
    "    'ngram_range':(3, 3), \n",
    "}\n",
    "df, d, v = tfidf(df_fea[tfidf_src_col].values, params, 'tfidf_word_33')\n",
    "dfs.append(df)\n",
    "fea_dict.update(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### smishing 1, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-01T09:36:52.987190Z",
     "start_time": "2020-01-01T09:36:52.984965Z"
    }
   },
   "source": [
    "##### char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T21:02:38.250202Z",
     "start_time": "2020-01-05T21:02:16.238977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_pos_char_11 (297571, 892)\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'analyzer' : 'char',\n",
    "#     'max_features':500, \n",
    "#     'vocabulary': vocab,\n",
    "    'stop_words':stop_words, \n",
    "#     'max_df':1.0, \n",
    "#     'min_df':100, \n",
    "    'ngram_range':(1, 1), \n",
    "}\n",
    "df, d, v = tfidf(df_fea[df_fea['smishing']==1][tfidf_src_col].values, params, 'tfidf_pos_char_11')\n",
    "dfs.append(df)\n",
    "fea_dict.update(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T21:02:52.943616Z",
     "start_time": "2020-01-05T21:02:38.251115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_pos_word_11 (297571, 1000)\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_features':1000,#500, \n",
    "#     'vocabulary': vocab,\n",
    "    'stop_words':stop_words, \n",
    "    'max_df':1.0, \n",
    "    'min_df':100, \n",
    "    'ngram_range':(1, 1), \n",
    "}\n",
    "df, d, v = tfidf(df_fea[df_fea['smishing']==1][tfidf_src_col].values, params, 'tfidf_pos_word_11')\n",
    "dfs.append(df)\n",
    "fea_dict.update(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### smishing 2, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T21:03:11.099835Z",
     "start_time": "2020-01-05T21:02:52.945269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_pos_word_22 (297571, 1000)\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_features':1000,#,500, \n",
    "#     'vocabulary': vocab,\n",
    "    'stop_words':stop_words, \n",
    "    'max_df':1.0, \n",
    "    'min_df':100, \n",
    "    'ngram_range':(2, 2), \n",
    "}\n",
    "df, d, v = tfidf(df_fea[df_fea['smishing']==1][tfidf_src_col].values, params, 'tfidf_pos_word_22')\n",
    "dfs.append(df)\n",
    "fea_dict.update(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T21:03:11.102360Z",
     "start_time": "2020-01-05T21:03:11.100854Z"
    }
   },
   "outputs": [],
   "source": [
    "# ts = '20191214T055747'\n",
    "# file_name = 'model/gensim_{}'.format(ts)\n",
    "\n",
    "# w2v_model = joblib.load(os.path.join(base_path, '{}.pkl'.format(file_name)))\n",
    "# w2v_size = w2v_model.wv.vectors.shape[1]\n",
    "\n",
    "# def mean_w2v(row):\n",
    "#     nouns = row['nouns']\n",
    "#     w2v = np.zeros(w2v_size)\n",
    "\n",
    "    \n",
    "#     for n in nouns:\n",
    "#         if n in w2v_model.wv.vocab.keys():\n",
    "#             w2v = np.add(w2v, w2v_model.wv[n])\n",
    "            \n",
    "#     return w2v if len(nouns) == 0 else np.true_divide(w2v, len(nouns))\n",
    "\n",
    "# w2v_cols = ['w2v_{}'.format(i) for i in range(w2v_size)]\n",
    "\n",
    "# df_fea[w2v_cols] = df_fea.apply(mean_w2v, axis=1, result_type='expand')\n",
    "\n",
    "# for c in w2v_cols:\n",
    "#     df_fea[c] = df_fea[c].astype(np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T21:03:40.129834Z",
     "start_time": "2020-01-05T21:03:11.103117Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 185503,
     "status": "ok",
     "timestamp": 1576287090605,
     "user": {
      "displayName": "주이클",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCWVh4nvn9788qUddhoWTl5qQoYt0bzVMDlJWUumTg=s64",
      "userId": "02708070532256873610"
     },
     "user_tz": -540
    },
    "id": "4f9oWotspZxF",
    "outputId": "6e0f2830-c6ef-4e00-9b0b-19ea6751dad0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297571, 147)\n",
      "(297571, 38)\n",
      "(297571, 999)\n",
      "(297571, 999)\n",
      "(297571, 3000)\n",
      "(297571, 3000)\n",
      "(297571, 1500)\n",
      "(297571, 892)\n",
      "(297571, 1000)\n",
      "(297571, 1000)\n",
      "df_merged (297571, 12575)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 297571 entries, 0 to 341625\n",
      "Columns: 12575 entries, year_month to tfidf_pos_word_22_0999\n",
      "dtypes: float16(12434), float32(88), int16(44), int64(1), object(8)\n",
      "memory usage: 7.0+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_fea.shape)\n",
    "for df in dfs:\n",
    "    print(df.shape)\n",
    "\n",
    "df_merged = pd.concat([df_fea] + dfs, axis=1)\n",
    "print('df_merged', df_merged.shape)\n",
    "print(df_merged.info())\n",
    "# df_merged.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T21:03:40.185166Z",
     "start_time": "2020-01-05T21:03:40.142005Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 185838,
     "status": "ok",
     "timestamp": 1576287091046,
     "user": {
      "displayName": "주이클",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCWVh4nvn9788qUddhoWTl5qQoYt0bzVMDlJWUumTg=s64",
      "userId": "02708070532256873610"
     },
     "user_tz": -540
    },
    "id": "QOi9dYzqpZxV",
    "outputId": "9ceb7e20-059e-4946-934e-ab85c98dca56",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12568, 12569, 49980, 128)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_cols = ['id', 'year_month', 'text', 'smishing', 'nouns', 'nouns_str', 'morphs', 'morphs_str']\n",
    "\n",
    "cat_cols = []\n",
    "fea_cols = [c for c in df_merged.columns if c not in idx_cols]\n",
    "\n",
    "for c in fea_cols:\n",
    "    if c not in fea_dict.keys():\n",
    "        fea_dict[c] = c\n",
    "\n",
    "len(fea_cols), len(fea_dict.keys()), vocab_dim, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T21:05:11.811022Z",
     "start_time": "2020-01-05T21:05:11.777581Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fea_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-038a93846b4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfea_cols\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfea_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fea_cols' is not defined"
     ]
    }
   ],
   "source": [
    "set(fea_cols) - set(fea_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T21:03:55.603063Z",
     "start_time": "2020-01-05T21:03:40.195656Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "dtoNNPnG75fT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_fea, df_train, df_test\n",
    "for df in dfs:\n",
    "    del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T21:03:55.623046Z",
     "start_time": "2020-01-05T21:03:55.604866Z"
    }
   },
   "outputs": [],
   "source": [
    "# base_dict = (df_merged[fea_cols].max() - df_merged[fea_cols].min()).to_dict()\n",
    "\n",
    "# for c in fea_cols:\n",
    "#     df_merged[c] = df_merged[c] / base_dict[c]\n",
    "\n",
    "# print(df_merged[fea_cols].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T21:04:23.280147Z",
     "start_time": "2020-01-05T21:03:55.625778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200106T060355_12568_128_49980\n"
     ]
    }
   ],
   "source": [
    "# merged_ts = datetime.now().strftime('%Y%m%dT%H%M%S') + '_' + str(len(fea_cols))\n",
    "merged_ts = '{}_{}_{}_{}'.format(datetime.now().strftime('%Y%m%dT%H%M%S'), \n",
    "                                 str(len(fea_cols)), \n",
    "                                 str(max_len), \n",
    "                                 str(vocab_dim))\n",
    "print(merged_ts)\n",
    "\n",
    "for c in df_merged:\n",
    "    if c not in fea_cols + ['smishing']:\n",
    "        df_merged.drop(c, axis=1, inplace=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T21:04:23.852070Z",
     "start_time": "2020-01-05T21:04:23.285389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 297571 entries, 0 to 341625\n",
      "Columns: 12569 entries, smishing to tfidf_pos_word_22_0999\n",
      "dtypes: float16(12434), float32(88), int16(44), int64(1), object(2)\n",
      "memory usage: 7.0+ GB\n"
     ]
    }
   ],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T21:04:23.952163Z",
     "start_time": "2020-01-05T21:04:23.853010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/df_merged_20200106T060355_12568_128_49980_fea_dict.pkl']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(fea_dict, 'data/df_merged_{}_fea_dict.pkl'.format(merged_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T21:04:47.328285Z",
     "start_time": "2020-01-05T21:04:23.953038Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/df_merged_20200106T060355_12568_128_49980_train.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(df_merged.loc[df_merged['smishing'] != -1,:], 'data/df_merged_{}_train.pkl'.format(merged_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T21:04:48.851710Z",
     "start_time": "2020-01-05T21:04:47.542423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/df_merged_20200106T060355_12568_128_49980_train_pos.pkl']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(df_merged.loc[df_merged['smishing'] == 1,:], 'data/df_merged_{}_train_pos.pkl'.format(merged_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T21:04:48.989458Z",
     "start_time": "2020-01-05T21:04:48.873351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/df_merged_20200106T060355_12568_128_49980_test.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(df_merged.loc[df_merged['smishing'] == -1,:], 'data/df_merged_{}_test.pkl'.format(merged_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T21:04:48.997546Z",
     "start_time": "2020-01-05T21:04:48.996029Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "dtoNNPnG75fT"
   },
   "outputs": [],
   "source": [
    "# del df_merged, df_fea, df_train, df_test\n",
    "# for df in dfs:\n",
    "#     del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T21:04:53.820348Z",
     "start_time": "2020-01-05T21:04:49.011663Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T21:04:53.831208Z",
     "start_time": "2020-01-05T21:04:53.829559Z"
    }
   },
   "outputs": [],
   "source": [
    "exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mecab_tfidf.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
