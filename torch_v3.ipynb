{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T04:20:19.680587Z",
     "start_time": "2020-01-04T04:20:18.469726Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1590,
     "status": "ok",
     "timestamp": 1576286906380,
     "user": {
      "displayName": "주이클",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCWVh4nvn9788qUddhoWTl5qQoYt0bzVMDlJWUumTg=s64",
      "userId": "02708070532256873610"
     },
     "user_tz": -540
    },
    "id": "U3xmRNtgpZwi",
    "outputId": "f6e95e03-5913-4a53-9ff3-1b6cde1b5a82"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.externals import joblib \n",
    "import os\n",
    "from konlpy.tag import Mecab\n",
    "import lightgbm as lgb\n",
    "print(lgb.__version__)\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.externals import joblib \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from tools import EarlyStopping, eval_summary\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RD_REV_Model(torch.nn.Module):\n",
    "    def __init__(self, input_size, vocab_size, embed_size, hidden_size, num_layers):\n",
    "        super(RD_REV_Model,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(p=0.1)\n",
    "        \n",
    "#         self.embed = torch.nn.Embedding(vocab_size, embed_size, sparse=True)\n",
    "        self.embed = torch.nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = torch.nn.LSTM(embed_size,\n",
    "                    hidden_size,\n",
    "                    num_layers,\n",
    "                    batch_first=True,\n",
    "                    bidirectional=False, \n",
    "#                      dropout=0.3\n",
    "                                 )\n",
    "        self.rev_lstm = torch.nn.LSTM(embed_size,\n",
    "                    hidden_size,\n",
    "                    num_layers,\n",
    "                    batch_first=True,\n",
    "                    bidirectional=False, \n",
    "#                      dropout=0.3\n",
    "                                     )\n",
    "        \n",
    "#         self.fc = torch.nn.Sequential(\n",
    "#             torch.nn.Linear(input_size, 2048), self.relu, torch.nn.BatchNorm1d(2048), self.dropout,\n",
    "#             torch.nn.Linear(2048, 1024), self.relu, torch.nn.BatchNorm1d(1024), self.dropout,\n",
    "# #             torch.nn.Linear(1024, 512), self.relu, torch.nn.BatchNorm1d(512), self.dropout,\n",
    "# #             torch.nn.Linear(512, 512), self.relu, torch.nn.BatchNorm1d(512), self.dropout,\n",
    "# #             torch.nn.Linear(512, 256), self.relu, torch.nn.BatchNorm1d(256), self.dropout,\n",
    "# #             torch.nn.Linear(256, 128), self.relu, torch.nn.BatchNorm1d(128), self.dropout,\n",
    "            \n",
    "#             torch.nn.Linear(1024, 128), self.relu, torch.nn.BatchNorm1d(128), self.dropout,\n",
    "# #             torch.nn.Linear(128, 2), \n",
    "#         )\n",
    "#         self.output = torch.nn.Linear(hidden_size + 128, 2)\n",
    "        \n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, 512), self.relu, torch.nn.BatchNorm1d(512), self.dropout,\n",
    "            torch.nn.Linear(512, 256), self.relu, torch.nn.BatchNorm1d(256), self.dropout,\n",
    "            torch.nn.Linear(256, 128), self.relu, torch.nn.BatchNorm1d(128), self.dropout,\n",
    "        )\n",
    "        \n",
    "        self.output = torch.nn.Linear(hidden_size * 2 + 128, 2)\n",
    "        \n",
    "#         self.output = torch.nn.Linear(hidden_size, 2)\n",
    "        \n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # (num_layers * num_directions, input_size, hidden_size)\n",
    "        hidden = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size)).to(device)\n",
    "        cell = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size)).to(device)\n",
    "        \n",
    "        rev_hidden = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size)).to(device)\n",
    "        rev_cell = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size)).to(device)\n",
    "        return hidden, cell, rev_hidden, rev_cell\n",
    "\n",
    "        \n",
    "    def forward(self, x, seq, rev_seq):   \n",
    "        embed = self.embed(seq)\n",
    "        rev_embed = self.embed(rev_seq)\n",
    "        \n",
    "        hidden, cell, rev_hidden, rev_cell = self.init_hidden(embed.size(0)) # initial hidden,cell\n",
    "        \n",
    "        out, (hidden, cell) = self.lstm(embed, (hidden, cell))\n",
    "        rev_out, (rev_hidden, rev_cell) = self.rev_lstm(rev_embed, (rev_hidden, rev_cell))\n",
    "        \n",
    "        hidden = hidden[-1:]\n",
    "        rev_hidden = rev_hidden[-1:]\n",
    "        merged = torch.cat([h for h in hidden] + [h for h in rev_hidden] + [self.fc(x)], 1)\n",
    "        \n",
    "#         merged = torch.cat([out, rev_out, self.fc(x)], 1)\n",
    "#         hidden = torch.cat([h for h in hidden], 1)\n",
    "        \n",
    "        return self.output(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T04:20:19.690911Z",
     "start_time": "2020-01-04T04:20:19.681698Z"
    }
   },
   "outputs": [],
   "source": [
    "class RDModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, vocab_size, embed_size, hidden_size, num_layers):\n",
    "        super(RDModel,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(p=0.1)\n",
    "        \n",
    "        self.embed = torch.nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = torch.nn.LSTM(embed_size,\n",
    "                    hidden_size,\n",
    "                    num_layers,\n",
    "                    batch_first=True,\n",
    "                    bidirectional=False, \n",
    "#                      dropout=0.3\n",
    "                                 )\n",
    "        \n",
    "#         self.fc = torch.nn.Sequential(\n",
    "#             torch.nn.Linear(input_size, 2048), self.relu, torch.nn.BatchNorm1d(2048), self.dropout,\n",
    "#             torch.nn.Linear(2048, 1024), self.relu, torch.nn.BatchNorm1d(1024), self.dropout,\n",
    "# #             torch.nn.Linear(1024, 512), self.relu, torch.nn.BatchNorm1d(512), self.dropout,\n",
    "# #             torch.nn.Linear(512, 512), self.relu, torch.nn.BatchNorm1d(512), self.dropout,\n",
    "# #             torch.nn.Linear(512, 256), self.relu, torch.nn.BatchNorm1d(256), self.dropout,\n",
    "# #             torch.nn.Linear(256, 128), self.relu, torch.nn.BatchNorm1d(128), self.dropout,\n",
    "            \n",
    "#             torch.nn.Linear(1024, 128), self.relu, torch.nn.BatchNorm1d(128), self.dropout,\n",
    "# #             torch.nn.Linear(128, 2), \n",
    "#         )\n",
    "#         self.output = torch.nn.Linear(hidden_size + 128, 2)\n",
    "        \n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, 512), self.relu, torch.nn.BatchNorm1d(512), self.dropout,\n",
    "            torch.nn.Linear(512, 256), self.relu, torch.nn.BatchNorm1d(256), self.dropout,\n",
    "            torch.nn.Linear(256, 128), self.relu, torch.nn.BatchNorm1d(128), self.dropout,\n",
    "        )\n",
    "        \n",
    "        self.output = torch.nn.Linear(hidden_size * 2 + 128, 2)\n",
    "        \n",
    "#         self.output = torch.nn.Linear(hidden_size, 2)\n",
    "        \n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # (num_layers * num_directions, input_size, hidden_size)\n",
    "        hidden = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size)).to(device)\n",
    "        cell = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size)).to(device)\n",
    "        \n",
    "        return hidden, cell, rev_hidden, rev_cell\n",
    "\n",
    "        \n",
    "    def forward(self, x, seq):   \n",
    "        embed = self.embed(seq)\n",
    "        \n",
    "        hidden, cell = self.init_hidden(embed.size(0)) # initial hidden,cell\n",
    "        \n",
    "        out, (hidden, cell) = self.lstm(embed, (hidden, cell))\n",
    "        \n",
    "        hidden = hidden[-1:]\n",
    "        merged = torch.cat([h for h in hidden] + [self.fc(x)], 1)\n",
    "        \n",
    "        return self.output(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T04:20:19.699836Z",
     "start_time": "2020-01-04T04:20:19.692014Z"
    }
   },
   "outputs": [],
   "source": [
    "class RDDataset(Dataset):\n",
    "    def __init__(self, df, y_col, seq_col='idx', rev_seq_col='ridx'):\n",
    "        self.seq_col = seq_col\n",
    "        self.rev_seq_col = rev_seq_col\n",
    "        self.cols = [c for c in df.columns if c not in [y_col, seq_col, rev_seq_col]]\n",
    "        \n",
    "        print(seq_col, rev_seq_col, len(self.cols), y_col)\n",
    "        \n",
    "        self.X = df[self.cols].values\n",
    "        self.y = pd.get_dummies(df[y_col].astype(int), prefix=y_col).values\n",
    "        \n",
    "        self.seq_X = np.stack(df[self.seq_col].values)        \n",
    "        self.rev_seq_X = np.stack(df[self.rev_seq_col].values)        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        return self.cols + [self.seq_col, self.rev_seq_col] \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X[idx].astype(np.float32)\n",
    "        X_seq = self.seq_X[idx].astype(np.int64)\n",
    "        X_rev_seq = self.rev_seq_X[idx].astype(np.int64)\n",
    "        y = self.y[idx].astype(np.float32)\n",
    "        \n",
    "#         print(X.shape, X_seq.shape, y.shape)\n",
    "        return X, X_seq, X_rev_seq, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train/test_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T04:20:19.715790Z",
     "start_time": "2020-01-04T04:20:19.701271Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_torch(dataset, step=100, num_workers=3):\n",
    "    model.train()\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    data_loader = DataLoader(dataset=dataset,\n",
    "#                           batch_size=100000,\n",
    "#                         batch_size=int(train_size * 0.7),\n",
    "                          batch_size=len(dataset) // step,\n",
    "#                           batch_size=10000,\n",
    "                          shuffle=True,\n",
    "                          num_workers=num_workers,\n",
    "                         drop_last=True\n",
    "                         )\n",
    "    for i, data in enumerate(data_loader):\n",
    "#     for i, data in tqdm_notebook(enumerate(train_loader), total=len(train_loader), desc = 'epoch{}_batch'.format(e)):\n",
    "        X_batch, X_seq_batch, X_rev_seq_batch, y_batch = data\n",
    "        \n",
    "        X_batch = X_batch.to(device)\n",
    "        X_seq_batch = X_seq_batch.to(device)\n",
    "        X_rev_seq_batch = X_rev_seq_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "#         print(X_batch.size())\n",
    "        \n",
    "        y_pred = model(X_batch, X_seq_batch, X_rev_seq_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        \n",
    "        loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        acc += (y_pred.argmax(1) == y_batch.argmax(1)).sum().item()\n",
    "        \n",
    "        del X_batch, y_batch, y_pred\n",
    "        gc.collect()\n",
    "\n",
    "    return loss / len(dataset), acc / len(dataset)\n",
    "\n",
    "\n",
    "def test_torch(dataset, step=100, num_workers=3):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    \n",
    "    y_true_list = []\n",
    "    y_score_list = []\n",
    "    \n",
    "    data_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=len(dataset) // step,\n",
    "                          shuffle=False,\n",
    "                          num_workers=num_workers,\n",
    "                          drop_last=True\n",
    "                         ) \n",
    "    \n",
    "    for i, data in enumerate(data_loader):\n",
    "        X_batch, X_seq_batch, X_rev_seq_batch, y_batch = data\n",
    "        y_true = y_batch\n",
    "        \n",
    "        X_batch = X_batch.to(device)\n",
    "        X_seq_batch = X_seq_batch.to(device)\n",
    "        X_rev_seq_batch = X_rev_seq_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        y_true_list.append(y_true[:, 1].cpu().detach().numpy())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_pred = model(X_batch, X_seq_batch, X_rev_seq_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss += loss.item()\n",
    "            acc += (y_pred.argmax(1) == y_batch.argmax(1)).sum().item()\n",
    "            \n",
    "            y_pred = torch.sigmoid(y_pred)\n",
    "            y_score_list.append(y_pred[:, 1].cpu().detach().numpy())\n",
    "            \n",
    "#              del X_batch, y_batch, y_true, y_pred\n",
    "            \n",
    "    return loss / len(dataset), acc / len(dataset), np.concatenate(y_true_list, axis=0), np.concatenate(y_score_list, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T04:20:19.723689Z",
     "start_time": "2020-01-04T04:20:19.716682Z"
    }
   },
   "outputs": [],
   "source": [
    "fc_cols = [\n",
    "#     'tfidf_pos_word_22_0028',\n",
    "#  'tfidf_pos_char_11_0000',\n",
    "#  'tfidf_word_11_1263',\n",
    "#  'tfidf_word_11_1516',\n",
    "#  'tfidf_word_11_0552',\n",
    "#  'cnt_0583',\n",
    "#  'tfidf_word_22_0130',\n",
    "#  'tfidf_word_11_0177',\n",
    "#  'tfidf_word_11_0307',\n",
    "#  'tfidf_word_22_0132',\n",
    "#  'tfidf_word_11_0928',\n",
    "#  'tfidf_word_11_0186',\n",
    "#  'cnt_0492',\n",
    "#  'tfidf_pos_word_11_0129',\n",
    "#  'tfidf_char_11_0264',\n",
    "#  'tfidf_pos_char_11_0650',\n",
    "#  'tfidf_pos_char_11_0242',\n",
    "#  'tfidf_char_11_0731',\n",
    "#  'tfidf_word_11_0916',\n",
    "#  'tfidf_pos_char_11_0213',\n",
    "#  'tfidf_pos_word_22_0021',\n",
    "#  'tfidf_char_11_0230',\n",
    "#  'tfidf_pos_word_11_0391',\n",
    "#  'cnt_0041',\n",
    "#  'cnt_0042',\n",
    "#  'tfidf_char_11_0796',\n",
    "#  'tfidf_word_22_0095',\n",
    "#  'tfidf_word_11_0011',\n",
    "#  'tfidf_word_11_0736',\n",
    "#  'tfidf_pos_char_11_0005',\n",
    "#  'tfidf_pos_word_11_0077',\n",
    "#  'fea__noun',\n",
    "#  'cnt_0126',\n",
    "#  'cnt_0223',\n",
    "#  'tfidf_word_11_1439',\n",
    "#  'tfidf_pos_char_11_0003',\n",
    "#  'tfidf_word_11_0854',\n",
    "#  'tfidf_word_11_1660',\n",
    "#  'tfidf_char_11_0359',\n",
    "#  'tfidf_pos_char_11_0589',\n",
    "#  'cnt_0715',\n",
    "#  'tfidf_pos_char_11_0415',\n",
    "#  'tfidf_pos_word_11_0235',\n",
    "#  'tfidf_char_11_0702',\n",
    "#  'tfidf_char_11_0464',\n",
    "#  'tfidf_pos_char_11_0017',\n",
    "#  'tfidf_word_11_0319',\n",
    "#  'tfidf_pos_char_11_0626',\n",
    "#  'tfidf_pos_word_11_0420',\n",
    "#  'tfidf_char_11_0657',\n",
    "#  'tfidf_word_22_0091',\n",
    "#  'cnt_0796',\n",
    "#  'tfidf_char_11_0126',\n",
    "#  'tfidf_word_11_0166',\n",
    "#  'tfidf_word_33_0026',\n",
    "#  'fea__text_len',\n",
    "#  'tfidf_char_11_0130',\n",
    "#  'tfidf_word_22_0134',\n",
    "#  'cnt_0007',\n",
    "#  'tfidf_pos_word_11_0044',\n",
    "#  'tfidf_pos_char_11_0007',\n",
    "#  'tfidf_pos_char_11_0324'\n",
    "          ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T04:20:32.061206Z",
     "start_time": "2020-01-04T04:20:19.724506Z"
    }
   },
   "outputs": [],
   "source": [
    "# merged_ts = '20191230T014439_8180'\n",
    "# merged_ts = '20191229T155539'\n",
    "# merged_ts = '20191231T113708_5499'\n",
    "# merged_ts = '20191231T165424_6099'\n",
    "# merged_ts = '20191231T162533_2022'\n",
    "# merged_ts = '20200101T212111_5854_100_24161'\n",
    "# merged_ts = '20200102T015155_8438_128_49980'\n",
    "# merged_ts = '20200103T111811_8438_256_1774'\n",
    "# merged_ts = '20200103T112827_8438_256_49980' # cv3 9458\n",
    "# merged_ts = '20200104T033010_10938_512_49980'\n",
    "\n",
    "merged_ts = '20200104T113831_10939_64_49980'\n",
    "\n",
    "train_path = 'data/df_merged_{}_train.pkl'.format(merged_ts)\n",
    "test_path = 'data/df_merged_{}_test.pkl'.format(merged_ts)\n",
    "\n",
    "df_model = joblib.load(train_path)  \n",
    "df_model = df_model.reset_index()\n",
    "print('model_set\\n', df_model['smishing'].value_counts())\n",
    "df_test = joblib.load(test_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T04:20:33.978421Z",
     "start_time": "2020-01-04T04:20:32.061913Z"
    }
   },
   "outputs": [],
   "source": [
    "idx_cols = ['smishing', 'id', 'index']\n",
    "\n",
    "seq_col = [c for c in df_model.columns if '_idx' in c][0]\n",
    "rev_seq_col = [c for c in df_model.columns if '_ridx' in c][0]\n",
    "\n",
    "fea_cols = [c for c in df_model.columns if c not in idx_cols + [seq_col, rev_seq_col]]\n",
    "\n",
    "# fea_cols = [c for c in fea_cols if c in fc_cols] + [c for c in df_model.columns if 'fea__' in c]\n",
    "\n",
    "fea_cols = list(set(fea_cols))\n",
    "\n",
    "# fea_cols.remove(seq_col)\n",
    "input_size = len(fea_cols)\n",
    "\n",
    "vocab_size = int(merged_ts.split('_')[-1])\n",
    "\n",
    "x_test = torch.Tensor(df_test[fea_cols].values).to(device)\n",
    "x_seq_test = torch.Tensor(np.stack(df_test[seq_col].values)).long().to(device)\n",
    "x_rev_seq_test = torch.Tensor(np.stack(df_test[rev_seq_col].values)).long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T04:20:33.982366Z",
     "start_time": "2020-01-04T04:20:33.979871Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size, len(fea_cols), seq_col, rev_seq_col, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T04:20:36.645614Z",
     "start_time": "2020-01-04T04:20:33.983199Z"
    }
   },
   "outputs": [],
   "source": [
    "df_model[fea_cols].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T04:59:02.455525Z",
     "start_time": "2020-01-04T04:20:36.646330Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params_dataloader = {\n",
    "    'step' : 12,\n",
    "    'num_workers': 2,\n",
    "}\n",
    "\n",
    "params_model = {\n",
    "    'input_size':input_size, \n",
    "    'vocab_size':vocab_size,\n",
    "    'embed_size':128, \n",
    "    'hidden_size':16,\n",
    "    'num_layers':2,\n",
    "}\n",
    "\n",
    "print('merged_ts', merged_ts)\n",
    "print(params_dataloader)\n",
    "print(params_model)\n",
    "\n",
    "[df_test.drop(c, axis=1, inplace=True) for c in df_test.columns if 'smishing_' in c]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=8405)\n",
    "\n",
    "for cv, index in enumerate(skf.split(df_model[fea_cols], df_model['smishing'])):\n",
    "    train_index, valid_index = index\n",
    "    train_set = RDDataset(df_model.loc[train_index, fea_cols + [seq_col, rev_seq_col, 'smishing']],\n",
    "                          'smishing', seq_col, rev_seq_col)\n",
    "    valid_set = RDDataset(df_model.loc[valid_index, fea_cols + [seq_col, rev_seq_col, 'smishing']],\n",
    "                          'smishing', seq_col, rev_seq_col)\n",
    "    \n",
    "    print(len(train_index), len(valid_index))\n",
    "    print('\\nCV', cv)\n",
    "    model = RDModel(**params_model).to(device)\n",
    "    \n",
    "    epoch = 1\n",
    "    if cv == 0:\n",
    "#         print(summary(model, (input_size, )))\n",
    "        print(model.train())\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=5, min_epoch=18, verbose=True)\n",
    "    \n",
    "    pos_weight = torch.Tensor([1., 10.,])\n",
    "#     pos_weight = torch.Tensor([1., 1.,])\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(reduction='sum', pos_weight=pos_weight).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "#     optimizer = torch.optim.SparseAdam(model.parameters(), lr = 0.0025)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=10, gamma=0.999)\n",
    "\n",
    "    model_ts = datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "    print('model_ts', model_ts)\n",
    "    print('Epoch:', epoch)\n",
    "\n",
    "    N_EPOCHS = 100\n",
    "    for e in tqdm_notebook(range(epoch, epoch + N_EPOCHS), total=N_EPOCHS, desc = 'CV {} Epoch'.format(cv)):\n",
    "        train_loss, train_acc = train_torch(train_set, **params_dataloader)\n",
    "        valid_loss, valid_acc, y_true, y_score = test_torch(valid_set, **params_dataloader)\n",
    "        print('[{}] CV {} Epoch {}\\n\\tTrain loss: {}\\tValid loss: {}\\t{}'.format(\n",
    "            datetime.now().strftime('%Y%m%dT%H%M%S'), \n",
    "            cv, e, train_loss, valid_loss, train_loss / valid_loss))\n",
    "        \n",
    "        eval_dict = eval_summary(y_true, y_score, cut_off=0.5)\n",
    "        print('\\t', eval_dict)\n",
    "        \n",
    "        early_stopping(-eval_dict['auc'], model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"\\tEarly stopping epoch {}, valid loss {}\".format(e, valid_loss))\n",
    "            break\n",
    "    \n",
    "        epoch = e + 1\n",
    "    \n",
    "    # load the last checkpoint with the best model\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    torch.save(model.state_dict(), 'model/{}_{}_{}.model'.format(model_ts, cv, early_stopping.best_epoch))\n",
    "    print('\\nBest_Epoch', early_stopping.best_epoch, 'auc', early_stopping.best_score)\n",
    "    \n",
    "    valid_loss, valid_acc, y_true, y_score = test_torch(valid_set)\n",
    "    valid_dict = eval_summary(y_true, y_score, cut_off=0.5)\n",
    "    print('END<valid> CV {} eval summary\\n'.format(cv), valid_dict)\n",
    "\n",
    "    train_loss, train_acc, y_true, y_score = test_torch(train_set)\n",
    "    train_dict = eval_summary(y_true, y_score, cut_off=0.5)\n",
    "    print('END<train> CV {} eval summary\\n'.format(cv), train_dict)\n",
    "    \n",
    "    print('train_auc - valid_auc:', train_dict['auc'] - valid_dict['auc'])\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    pred_col = 'smishing_{}'.format(cv)\n",
    "    df_test[pred_col] = torch.sigmoid(model(x_test, x_seq_test, x_rev_seq_test))[:, 1].cpu().detach().numpy()\n",
    "    df_test[[pred_col]].to_csv('submit/{}_{}_nn.csv'.format(model_ts, pred_col), index=True)\n",
    "    \n",
    "    del train_set, valid_set\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T04:59:02.727571Z",
     "start_time": "2020-01-04T04:59:02.458469Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.Series(y_score)\n",
    "df.hist(bins=100, figsize=(20, 5))\n",
    "(df * 10).astype(int).value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T04:59:02.730278Z",
     "start_time": "2020-01-04T04:59:02.728637Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_model[(y_score <= 0.5) & (y_true == 1)]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T04:59:02.736161Z",
     "start_time": "2020-01-04T04:59:02.731231Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_model[(y_score > 0.5) & (y_true == 0)]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T04:59:02.760236Z",
     "start_time": "2020-01-04T04:59:02.737314Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_cols = [c for c in df_test.columns if 'smishing_' in c]\n",
    "print(len(pred_cols))\n",
    "df_test['pred_max'] = df_test[pred_cols].max(axis=1)\n",
    "df_test['pred_min'] = df_test[pred_cols].min(axis=1)\n",
    "df_test['pred_mean'] = df_test[pred_cols].mean(axis=1)\n",
    "df_test['pred_std'] = df_test[pred_cols].std(axis=1)\n",
    "\n",
    "print(df_test['pred_std'].max(), df_test['pred_std'].min(), df_test['pred_std'].mean())\n",
    "\n",
    "df_test['smishing'] = df_test['pred_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T04:59:02.959104Z",
     "start_time": "2020-01-04T04:59:02.761105Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test['smishing'].hist(bins=100, figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T04:59:02.969002Z",
     "start_time": "2020-01-04T04:59:02.962651Z"
    }
   },
   "outputs": [],
   "source": [
    "for c in pred_cols:\n",
    "    print(c)\n",
    "    print((df_test[c] * 10).astype(int).value_counts(sort=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T04:59:02.975840Z",
     "start_time": "2020-01-04T04:59:02.969892Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 0     1504\n",
    "# 1       11\n",
    "# 2        6\n",
    "# 3        6\n",
    "# 4        2\n",
    "# 5        3\n",
    "# 6        2\n",
    "# 9       39\n",
    "# 10      53\n",
    "(df_test['smishing'] * 10).astype(int).value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T04:59:02.981544Z",
     "start_time": "2020-01-04T04:59:02.977027Z"
    }
   },
   "outputs": [],
   "source": [
    "model_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T04:59:02.992953Z",
     "start_time": "2020-01-04T04:59:02.982653Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test[['smishing']].to_csv('submit/{}_nn.csv'.format(model_ts), index=True)\n",
    "# df_test[['id', 'smishing', 'text']].sort_values('smishing', ascending=False).to_csv('{}_text.csv'.format(model_ts), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dtoNNPnG75fT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mecab_tfidf.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
