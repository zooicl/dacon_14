{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-26T12:25:34.821587Z",
     "start_time": "2019-12-26T12:25:34.230244Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1590,
     "status": "ok",
     "timestamp": 1576286906380,
     "user": {
      "displayName": "주이클",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCWVh4nvn9788qUddhoWTl5qQoYt0bzVMDlJWUumTg=s64",
      "userId": "02708070532256873610"
     },
     "user_tz": -540
    },
    "id": "U3xmRNtgpZwi",
    "outputId": "f6e95e03-5913-4a53-9ff3-1b6cde1b5a82"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiden/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.2\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.externals import joblib \n",
    "import os\n",
    "from konlpy.tag import Mecab\n",
    "import lightgbm as lgb\n",
    "print(lgb.__version__)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "base_path = '.'\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(base_path , 'input/train.csv'), index_col=0)\n",
    "df_test = pd.read_csv(os.path.join(base_path , 'input/public_test.csv'), index_col=0)\n",
    "df_test['smishing'] = -1\n",
    "\n",
    "df_fea = pd.concat([df_train, df_test])\n",
    "df_fea.shape\n",
    "\n",
    "\n",
    "train_size = len(df_train)\n",
    "\n",
    "### Mecab\n",
    "\n",
    "# mecab = Mecab()\n",
    "# # df_space['morphs'] = df_space['spacing'].apply(lambda x: mecab.morphs(x))\n",
    "# df_fea['nouns'] = df_fea['text'].apply(lambda x: mecab.nouns(x))\n",
    "\n",
    "# df_fea['nouns_str'] = df_fea['nouns'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# df_fea.to_pickle('df_fea.pkl')\n",
    "\n",
    "df_fea = pd.read_pickle('data/df_fea.pkl')\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_data = df_fea[:train_size]['nouns_str'].values\n",
    "y_data = df_fea['smishing'].values\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_data) \n",
    "sequences = tokenizer.texts_to_sequences(X_data)\n",
    "\n",
    "X_data\n",
    "\n",
    "word_to_index = tokenizer.word_index\n",
    "print(word_to_index)\n",
    "\n",
    "vocab_size = len(word_to_index) + 1\n",
    "print('단어 집합의 크기: {}'.format((vocab_size)))\n",
    "\n",
    "n_of_train = int(train_size * 0.8)\n",
    "n_of_test = int(train_size - n_of_train)\n",
    "print(n_of_train)\n",
    "print(n_of_test)\n",
    "\n",
    "X_data = sequences\n",
    "max_len = max(len(l) for l in X_data)\n",
    "print('메일의 최대 길이 : %d' % max(len(l) for l in X_data))\n",
    "print('메일의 평균 길이 : %f' % (sum(map(len, X_data))/len(X_data)))\n",
    "plt.hist([len(s) for s in X_data], bins=50)\n",
    "plt.xlabel('length of Data')\n",
    "plt.ylabel('number of Data')\n",
    "plt.show()\n",
    "\n",
    "data = pad_sequences(X_data, maxlen=max_len)\n",
    "print(\"data shape: \", data.shape)\n",
    "\n",
    "X_test = data[n_of_train:] #X_data 데이터 중에서 뒤의 1115개의 데이터만 저장\n",
    "y_test = np.array(y_data[n_of_train:]) #y_data 데이터 중에서 뒤의 1115개의 데이터만 저장\n",
    "X_train = data[:n_of_train] #X_data 데이터 중에서 앞의 4457개의 데이터만 저장\n",
    "y_train = np.array(y_data[:n_of_train]) #y_data 데이터 중에서 앞의 4457개의 데이터만 저장\n",
    "\n",
    "### RNN\n",
    "\n",
    "from tensorflow.keras.layers import SimpleRNN, Embedding, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import tensorflow as tf\n",
    "with tf.device('/device:XLA_GPU:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 32)) # 임베딩 벡터의 차원은 32\n",
    "    model.add(SimpleRNN(32)) # RNN 셀의 hidden_size는 32\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = model.fit(X_train, y_train, epochs=4, batch_size=64, validation_split=0.2)\n",
    "\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mecab_tfidf.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
