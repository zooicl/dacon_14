{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T13:46:25.077498Z",
     "start_time": "2020-01-04T13:46:23.821750Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1590,
     "status": "ok",
     "timestamp": 1576286906380,
     "user": {
      "displayName": "주이클",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCWVh4nvn9788qUddhoWTl5qQoYt0bzVMDlJWUumTg=s64",
      "userId": "02708070532256873610"
     },
     "user_tz": -540
    },
    "id": "U3xmRNtgpZwi",
    "outputId": "f6e95e03-5913-4a53-9ff3-1b6cde1b5a82"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.externals import joblib \n",
    "import os\n",
    "from konlpy.tag import Mecab\n",
    "import lightgbm as lgb\n",
    "print(lgb.__version__)\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.externals import joblib \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from tools import EarlyStopping, eval_summary\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T13:46:25.080245Z",
     "start_time": "2020-01-04T13:46:25.078655Z"
    }
   },
   "outputs": [],
   "source": [
    "# from torch_design.rnn_fc import RNN_FC_Model as Model\n",
    "# from torch_design.rnn_fc import RNN_FC_Dataset as Dataset\n",
    "# from torch_design.rnn_fc import train_torch\n",
    "# from torch_design.rnn_fc import test_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T13:46:25.088000Z",
     "start_time": "2020-01-04T13:46:25.081432Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch_design.basic_nn import NN_Model as Model\n",
    "from torch_design.basic_nn import NN_Dataset as Dataset\n",
    "from torch_design.basic_nn import train_torch\n",
    "from torch_design.basic_nn import test_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T13:46:25.092448Z",
     "start_time": "2020-01-04T13:46:25.089089Z"
    }
   },
   "outputs": [],
   "source": [
    "fc_cols = [\n",
    "#     'tfidf_pos_word_22_0028',\n",
    "#  'tfidf_pos_char_11_0000',\n",
    "#  'tfidf_word_11_1263',\n",
    "#  'tfidf_word_11_1516',\n",
    "#  'tfidf_word_11_0552',\n",
    "#  'cnt_0583',\n",
    "#  'tfidf_word_22_0130',\n",
    "#  'tfidf_word_11_0177',\n",
    "#  'tfidf_word_11_0307',\n",
    "#  'tfidf_word_22_0132',\n",
    "#  'tfidf_word_11_0928',\n",
    "#  'tfidf_word_11_0186',\n",
    "#  'cnt_0492',\n",
    "#  'tfidf_pos_word_11_0129',\n",
    "#  'tfidf_char_11_0264',\n",
    "#  'tfidf_pos_char_11_0650',\n",
    "#  'tfidf_pos_char_11_0242',\n",
    "#  'tfidf_char_11_0731',\n",
    "#  'tfidf_word_11_0916',\n",
    "#  'tfidf_pos_char_11_0213',\n",
    "#  'tfidf_pos_word_22_0021',\n",
    "#  'tfidf_char_11_0230',\n",
    "#  'tfidf_pos_word_11_0391',\n",
    "#  'cnt_0041',\n",
    "#  'cnt_0042',\n",
    "#  'tfidf_char_11_0796',\n",
    "#  'tfidf_word_22_0095',\n",
    "#  'tfidf_word_11_0011',\n",
    "#  'tfidf_word_11_0736',\n",
    "#  'tfidf_pos_char_11_0005',\n",
    "#  'tfidf_pos_word_11_0077',\n",
    "#  'fea__noun',\n",
    "#  'cnt_0126',\n",
    "#  'cnt_0223',\n",
    "#  'tfidf_word_11_1439',\n",
    "#  'tfidf_pos_char_11_0003',\n",
    "#  'tfidf_word_11_0854',\n",
    "#  'tfidf_word_11_1660',\n",
    "#  'tfidf_char_11_0359',\n",
    "#  'tfidf_pos_char_11_0589',\n",
    "#  'cnt_0715',\n",
    "#  'tfidf_pos_char_11_0415',\n",
    "#  'tfidf_pos_word_11_0235',\n",
    "#  'tfidf_char_11_0702',\n",
    "#  'tfidf_char_11_0464',\n",
    "#  'tfidf_pos_char_11_0017',\n",
    "#  'tfidf_word_11_0319',\n",
    "#  'tfidf_pos_char_11_0626',\n",
    "#  'tfidf_pos_word_11_0420',\n",
    "#  'tfidf_char_11_0657',\n",
    "#  'tfidf_word_22_0091',\n",
    "#  'cnt_0796',\n",
    "#  'tfidf_char_11_0126',\n",
    "#  'tfidf_word_11_0166',\n",
    "#  'tfidf_word_33_0026',\n",
    "#  'fea__text_len',\n",
    "#  'tfidf_char_11_0130',\n",
    "#  'tfidf_word_22_0134',\n",
    "#  'cnt_0007',\n",
    "#  'tfidf_pos_word_11_0044',\n",
    "#  'tfidf_pos_char_11_0007',\n",
    "#  'tfidf_pos_char_11_0324'\n",
    "          ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T13:46:36.575943Z",
     "start_time": "2020-01-04T13:46:25.093372Z"
    }
   },
   "outputs": [],
   "source": [
    "# merged_ts = '20191230T014439_8180'\n",
    "# merged_ts = '20191229T155539'\n",
    "# merged_ts = '20191231T113708_5499'\n",
    "# merged_ts = '20191231T165424_6099'\n",
    "# merged_ts = '20191231T162533_2022'\n",
    "# merged_ts = '20200101T212111_5854_100_24161'\n",
    "# merged_ts = '20200102T015155_8438_128_49980'\n",
    "# merged_ts = '20200103T111811_8438_256_1774'\n",
    "# merged_ts = '20200103T112827_8438_256_49980' # cv3 9458\n",
    "# merged_ts = '20200104T033010_10938_512_49980'\n",
    "\n",
    "\n",
    "merged_ts = '20200104T151347_9528_64_49980'\n",
    "\n",
    "train_path = 'data/df_merged_{}_train.pkl'.format(merged_ts)\n",
    "test_path = 'data/df_merged_{}_test.pkl'.format(merged_ts)\n",
    "\n",
    "df_model = joblib.load(train_path)  \n",
    "df_model = df_model.reset_index()\n",
    "print('model_set\\n', df_model['smishing'].value_counts())\n",
    "df_test = joblib.load(test_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T13:46:38.382948Z",
     "start_time": "2020-01-04T13:46:36.576768Z"
    }
   },
   "outputs": [],
   "source": [
    "idx_cols = ['smishing', 'id', 'index']\n",
    "\n",
    "seq_col = [c for c in df_model.columns if '_idx' in c][0]\n",
    "rev_seq_col = [c for c in df_model.columns if '_ridx' in c][0]\n",
    "\n",
    "fea_cols = [c for c in df_model.columns if c not in idx_cols + [seq_col, rev_seq_col]]\n",
    "\n",
    "# fea_cols = [c for c in fea_cols if c in fc_cols] + [c for c in df_model.columns if 'fea__' in c]\n",
    "\n",
    "fea_cols = list(set(fea_cols))\n",
    "\n",
    "# fea_cols.remove(seq_col)\n",
    "input_size = len(fea_cols)\n",
    "\n",
    "vocab_size = int(merged_ts.split('_')[-1])\n",
    "\n",
    "x_test = torch.Tensor(df_test[fea_cols].values).to(device)\n",
    "x_seq_test = torch.Tensor(np.stack(df_test[seq_col].values)).long().to(device)\n",
    "x_rev_seq_test = torch.Tensor(np.stack(df_test[rev_seq_col].values)).long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T13:46:38.385999Z",
     "start_time": "2020-01-04T13:46:38.383686Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size, len(fea_cols), seq_col, rev_seq_col, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T13:46:40.062623Z",
     "start_time": "2020-01-04T13:46:38.387083Z"
    }
   },
   "outputs": [],
   "source": [
    "df_model[fea_cols].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T16:24:16.661627Z",
     "start_time": "2020-01-04T14:04:47.410372Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params_dataloader = {\n",
    "    'step' : 10,\n",
    "    'num_workers': 2,\n",
    "}\n",
    "\n",
    "params_model = {\n",
    "    'input_size':input_size, \n",
    "#     'vocab_size':vocab_size,\n",
    "#     'embed_size':128, \n",
    "#     'hidden_size':16,\n",
    "#     'num_layers':2,\n",
    "    'device': device,\n",
    "    'hidden_layers' : [4096, 2048, 1024, 1024, 512, 256]\n",
    "}\n",
    "\n",
    "print('merged_ts', merged_ts)\n",
    "print(params_dataloader)\n",
    "print(params_model)\n",
    "\n",
    "[df_test.drop(c, axis=1, inplace=True) for c in df_test.columns if 'smishing_' in c]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=8405)\n",
    "\n",
    "for cv, index in enumerate(skf.split(df_model[fea_cols], df_model['smishing'])):\n",
    "    train_index, valid_index = index\n",
    "    train_set = Dataset(df_model.loc[train_index, fea_cols + ['smishing']],\n",
    "                          'smishing')#, seq_col)\n",
    "    valid_set = Dataset(df_model.loc[valid_index, fea_cols + ['smishing']],\n",
    "                          'smishing')#, seq_col)\n",
    "    \n",
    "    print(len(train_index), len(valid_index))\n",
    "    print('\\nCV', cv)\n",
    "    model = Model(**params_model).to(device)\n",
    "    \n",
    "    epoch = 1\n",
    "    if cv == 0:\n",
    "#         print(summary(model, (input_size, )))\n",
    "        print(model.train())\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=10, min_epoch=100, verbose=True)\n",
    "    \n",
    "    pos_weight = torch.Tensor([1., 10.,])\n",
    "#     pos_weight = torch.Tensor([1., 1.,])\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(reduction='sum', pos_weight=pos_weight).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=10, gamma=0.9)\n",
    "\n",
    "    model_ts = datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "    print('model_ts', model_ts)\n",
    "    print('Epoch:', epoch)\n",
    "\n",
    "    N_EPOCHS = 100\n",
    "    for e in tqdm_notebook(range(epoch, epoch + N_EPOCHS), total=N_EPOCHS, desc = 'CV {} Epoch'.format(cv)):\n",
    "        train_loss, train_acc = train_torch(model, train_set, criterion, optimizer, scheduler, device, \n",
    "                                            **params_dataloader)\n",
    "        valid_loss, valid_acc, y_true, y_score = test_torch(model, valid_set, criterion, device,\n",
    "                                                            **params_dataloader)\n",
    "        print('[{}] CV {} Epoch {}\\n\\tTrain loss: {}\\tValid loss: {}\\t{}\\n\\t Train Acc: {}\\t Valid Acc:{}'.format(\n",
    "            datetime.now().strftime('%Y%m%dT%H%M%S'), \n",
    "            cv, e, train_loss, valid_loss, train_loss / valid_loss , train_acc, valid_acc))\n",
    "        \n",
    "        eval_dict = eval_summary(y_true, y_score, cut_off=0.5)\n",
    "        print('\\t', eval_dict)\n",
    "        \n",
    "        early_stopping(-eval_dict['auc'], model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"\\tEarly stopping epoch {}, valid loss {}\".format(e, valid_loss))\n",
    "            break\n",
    "    \n",
    "        epoch = e + 1\n",
    "    \n",
    "    # load the last checkpoint with the best model\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    torch.save(model.state_dict(), 'model/{}_{}_{}.model'.format(model_ts, cv, early_stopping.best_epoch))\n",
    "    print('\\nBest_Epoch', early_stopping.best_epoch, 'auc', early_stopping.best_score)\n",
    "    \n",
    "    valid_loss, valid_acc, y_true, y_score = test_torch(model, valid_set, criterion, device, **params_dataloader)\n",
    "    valid_dict = eval_summary(y_true, y_score, cut_off=0.5)\n",
    "    print('END<valid> CV {} eval summary\\n'.format(cv), valid_dict)\n",
    "    \n",
    "    train_loss, train_acc, y_true, y_score = test_torch(model, train_set, criterion, device, **params_dataloader)\n",
    "    train_dict = eval_summary(y_true, y_score, cut_off=0.5)\n",
    "    print('END<train> CV {} eval summary\\n'.format(cv), train_dict)\n",
    "    \n",
    "    print('train_auc - valid_auc:', train_dict['auc'] - valid_dict['auc'])\n",
    "    \n",
    "    model.eval()\n",
    "    pred_col = 'smishing_{}'.format(cv)\n",
    "    df_test[pred_col] = torch.sigmoid(model(x_test))[:, 1].cpu().detach().numpy()\n",
    "    df_test[[pred_col]].to_csv('submit/{}_{}_nn.csv'.format(model_ts, pred_col), index=True)\n",
    "    \n",
    "    del train_set, valid_set\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T14:04:25.927410Z",
     "start_time": "2020-01-04T13:46:23.855Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.Series(y_score)\n",
    "df.hist(bins=100, figsize=(20, 5))\n",
    "(df * 10).astype(int).value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T14:04:25.928013Z",
     "start_time": "2020-01-04T13:46:23.857Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_model[(y_score <= 0.5) & (y_true == 1)]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T14:04:25.928629Z",
     "start_time": "2020-01-04T13:46:23.859Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_model[(y_score > 0.5) & (y_true == 0)]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T14:04:25.929228Z",
     "start_time": "2020-01-04T13:46:23.862Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_cols = [c for c in df_test.columns if 'smishing_' in c]\n",
    "print(len(pred_cols))\n",
    "df_test['pred_max'] = df_test[pred_cols].max(axis=1)\n",
    "df_test['pred_min'] = df_test[pred_cols].min(axis=1)\n",
    "df_test['pred_mean'] = df_test[pred_cols].mean(axis=1)\n",
    "df_test['pred_std'] = df_test[pred_cols].std(axis=1)\n",
    "\n",
    "print(df_test['pred_std'].max(), df_test['pred_std'].min(), df_test['pred_std'].mean())\n",
    "\n",
    "df_test['smishing'] = df_test['pred_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T14:04:25.929859Z",
     "start_time": "2020-01-04T13:46:23.864Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test['smishing'].hist(bins=100, figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T14:04:25.930464Z",
     "start_time": "2020-01-04T13:46:23.865Z"
    }
   },
   "outputs": [],
   "source": [
    "for c in pred_cols:\n",
    "    print(c)\n",
    "    print((df_test[c] * 10).astype(int).value_counts(sort=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T14:04:25.930981Z",
     "start_time": "2020-01-04T13:46:23.867Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(df_test['smishing'] * 10).astype(int).value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T14:04:25.931502Z",
     "start_time": "2020-01-04T13:46:23.870Z"
    }
   },
   "outputs": [],
   "source": [
    "model_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-04T14:04:25.931950Z",
     "start_time": "2020-01-04T13:46:23.873Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test[['smishing']].to_csv('submit/{}_nn.csv'.format(model_ts), index=True)\n",
    "# df_test[['id', 'smishing', 'text']].sort_values('smishing', ascending=False).to_csv('{}_text.csv'.format(model_ts), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dtoNNPnG75fT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mecab_tfidf.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
