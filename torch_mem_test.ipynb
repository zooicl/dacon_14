{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T11:21:48.261637Z",
     "start_time": "2019-12-31T11:21:47.008741Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1590,
     "status": "ok",
     "timestamp": 1576286906380,
     "user": {
      "displayName": "주이클",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCWVh4nvn9788qUddhoWTl5qQoYt0bzVMDlJWUumTg=s64",
      "userId": "02708070532256873610"
     },
     "user_tz": -540
    },
    "id": "U3xmRNtgpZwi",
    "outputId": "f6e95e03-5913-4a53-9ff3-1b6cde1b5a82"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.externals import joblib \n",
    "import os\n",
    "from konlpy.tag import Mecab\n",
    "import lightgbm as lgb\n",
    "print(lgb.__version__)\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.externals import joblib \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T11:21:48.265170Z",
     "start_time": "2019-12-31T11:21:48.262478Z"
    }
   },
   "outputs": [],
   "source": [
    "class LRModel(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LRModel,self).__init__()\n",
    "\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, 2), \n",
    "#             torch.nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        return self.model(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T11:21:48.273769Z",
     "start_time": "2019-12-31T11:21:48.266305Z"
    }
   },
   "outputs": [],
   "source": [
    "class NNModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, dropout_probability=0.3):\n",
    "        super(NNModel,self).__init__()\n",
    "        relu = torch.nn.ReLU()\n",
    "        dropout = torch.nn.Dropout(p=dropout_probability)\n",
    "\n",
    "        self.model = torch.nn.Sequential(\n",
    "#             torch.nn.Linear(input_size, 4096), relu, torch.nn.BatchNorm1d(4096), dropout,\n",
    "#             torch.nn.Linear(4096, 2048), relu, torch.nn.BatchNorm1d(2048), dropout,\n",
    "            \n",
    "            torch.nn.Linear(input_size, 2048), relu, torch.nn.BatchNorm1d(2048), dropout,\n",
    "            torch.nn.Linear(2048, 1024), relu, torch.nn.BatchNorm1d(1024), dropout,\n",
    "            \n",
    "#             torch.nn.Linear(input_size, 1024), relu, torch.nn.BatchNorm1d(1024), dropout, \n",
    "\n",
    "            torch.nn.Linear(1024, 512), relu, torch.nn.BatchNorm1d(512), dropout,\n",
    "            torch.nn.Linear(512, 512), relu, torch.nn.BatchNorm1d(512), dropout,\n",
    "            torch.nn.Linear(512, 256), relu, torch.nn.BatchNorm1d(256), dropout,\n",
    "            torch.nn.Linear(256, 128), relu, torch.nn.BatchNorm1d(128), dropout,\n",
    "            torch.nn.Linear(128, 2), \n",
    "#             torch.nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        return self.model(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T11:21:49.638672Z",
     "start_time": "2019-12-31T11:21:48.274652Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = torch.ones(1).to(device)\n",
    "\n",
    "temp2 = torch.ones(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T11:21:51.570628Z",
     "start_time": "2019-12-31T11:21:49.639646Z"
    }
   },
   "outputs": [],
   "source": [
    "merged_ts = '20191231T165424_6099'\n",
    "train_path = 'data/df_merged_{}_train.pkl'.format(merged_ts)\n",
    "\n",
    "df_model = joblib.load(train_path)\n",
    "df_model.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T11:21:51.573575Z",
     "start_time": "2019-12-31T11:21:51.571602Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df_model[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T11:21:51.841560Z",
     "start_time": "2019-12-31T11:21:51.574350Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T11:21:52.359625Z",
     "start_time": "2019-12-31T11:21:51.842568Z"
    }
   },
   "outputs": [],
   "source": [
    "df_32 = df.astype(np.float32)\n",
    "df_32.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T11:22:13.434779Z",
     "start_time": "2019-12-31T11:22:13.217690Z"
    }
   },
   "outputs": [],
   "source": [
    "x_gpu = torch.Tensor(df_32.values).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T11:22:13.437840Z",
     "start_time": "2019-12-31T11:22:13.435649Z"
    }
   },
   "outputs": [],
   "source": [
    "y_gpu = torch.Tensor(df_32['smishing'].values).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T11:22:27.899609Z",
     "start_time": "2019-12-31T11:22:27.896307Z"
    }
   },
   "outputs": [],
   "source": [
    "linear = torch.nn.Linear(x_gpu.size()[1], 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T11:22:35.086639Z",
     "start_time": "2019-12-31T11:22:34.933569Z"
    }
   },
   "outputs": [],
   "source": [
    "o1 = linear(x_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T11:22:42.930177Z",
     "start_time": "2019-12-31T11:22:42.920910Z"
    }
   },
   "outputs": [],
   "source": [
    "o1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T11:23:02.081639Z",
     "start_time": "2019-12-31T11:23:01.972922Z"
    }
   },
   "outputs": [],
   "source": [
    "output = torch.sigmoid(o1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T11:23:12.012616Z",
     "start_time": "2019-12-31T11:23:12.008177Z"
    }
   },
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T08:25:21.497741Z",
     "start_time": "2019-12-31T08:25:21.496429Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = NNModel(input_size=input_size, dropout_probability=0.7).to(device)\n",
    "# epoch = 1\n",
    "# print(summary(model, (input_size, )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T08:25:21.510798Z",
     "start_time": "2019-12-31T08:25:21.498459Z"
    }
   },
   "outputs": [],
   "source": [
    "# import EarlyStopping\n",
    "from torchtools import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T08:25:14.891Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "[df_test.drop(c, axis=1, inplace=True) for c in df_test.columns if 'smishing_' in c]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=8405)\n",
    "\n",
    "for cv, index in enumerate(skf.split(df_model[fea_cols], df_model['smishing'])):\n",
    "    train_index, valid_index = index\n",
    "    \n",
    "    print(len(train_index), len(valid_index))\n",
    "    print('\\nCV', cv)\n",
    "    model = NNModel(input_size=input_size, dropout_probability=0.7).to(device)\n",
    "#     model =  LRModel(input_size=input_size).to(device)\n",
    "\n",
    "    # initialize the early_stopping object\n",
    "    early_stopping = EarlyStopping(patience=15, verbose=True)\n",
    "\n",
    "    epoch = 1\n",
    "    if cv == 0:\n",
    "        print(summary(model, (input_size, )))\n",
    "    \n",
    "    pos_weight = torch.Tensor([1., 10.,])\n",
    "#     pos_weight = torch.Tensor([1., 1.,])\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(reduction='sum', pos_weight=pos_weight).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "    model_ts = datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "    print(model_ts)\n",
    "    print('Epoch:', epoch)\n",
    "\n",
    "    N_EPOCHS = 100\n",
    "    is_summary = True\n",
    "    for e in tqdm_notebook(range(epoch, epoch + N_EPOCHS), total=N_EPOCHS, desc = 'CV {} Epoch'.format(cv)):\n",
    "        start_time = time.time()\n",
    "        train_set = KBDataset(df_model.loc[train_index, fea_cols + ['smishing']], 'smishing')\n",
    "        valid_set = KBDataset(df_model.loc[valid_index, fea_cols + ['smishing']], 'smishing')\n",
    "\n",
    "        train_loss, train_acc = train_torch(train_set)\n",
    "        valid_loss, valid_acc = test_torch(valid_set)\n",
    "        print('CV {} Epoch {}\\n\\tTrain loss: {}\\tValid loss: {}\\t{}'.format(cv, e, train_loss, valid_loss, train_loss / valid_loss))\n",
    "        \n",
    "        early_stopping(valid_loss, model)\n",
    "        \n",
    "        \n",
    "        if early_stopping.counter == 0:\n",
    "            if is_summary:\n",
    "                _, _, y_true, y_score = pred_torch(valid_set)            \n",
    "                print('\\t', eval_summary(y_true, y_score, cut_off=0.5))\n",
    "                is_summary = False\n",
    "        else:\n",
    "            is_summary = True\n",
    "            \n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"\\tEarly stopping epoch {}, valid loss {}\".format(e, valid_loss))\n",
    "            break\n",
    "    \n",
    "        del train_set, valid_set\n",
    "        gc.collect()\n",
    "        \n",
    "        epoch = e + 1\n",
    "    \n",
    "    # load the last checkpoint with the best model\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    \n",
    "    valid_set = KBDataset(df_model.loc[valid_index, fea_cols + ['smishing']], 'smishing')\n",
    "    _, _, y_true, y_score = pred_torch(valid_set)            \n",
    "    print('\\t', eval_summary(y_true, y_score, cut_off=0.5))\n",
    "\n",
    "    train_set = KBDataset(df_model.loc[train_index, fea_cols + ['smishing']], 'smishing')\n",
    "    _, _, y_true, y_score = pred_torch(train_set)            \n",
    "    print('END CV {} eval summary (train)\\n'.format(cv), eval_summary(y_true, y_score, cut_off=0.5))\n",
    "\n",
    "    torch.save(model.state_dict(), 'model/{}_{}_{}.model'.format(model_ts, cv, epoch-1))\n",
    "    \n",
    "    model.eval()\n",
    "    pred_col = 'smishing_{}'.format(cv)\n",
    "    df_test[pred_col] = torch.sigmoid(model(x_test))[:, 1].cpu().detach().numpy()\n",
    "    df_test[[pred_col]].to_csv('submit/{}_{}_nn.csv'.format(model_ts, pred_col), index=True)\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T08:25:14.894Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.Series(y_score)\n",
    "df.hist(bins=100, figsize=(20, 5))\n",
    "(df * 10).astype(int).value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T08:25:14.896Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_model[(y_score <= 0.5) & (y_true == 1)]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T08:25:14.897Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_model[(y_score > 0.5) & (y_true == 0)]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T08:25:14.899Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_cols = [c for c in df_test.columns if 'smishing_' in c]\n",
    "print(len(pred_cols))\n",
    "df_test['pred_max'] = df_test[pred_cols].max(axis=1)\n",
    "df_test['pred_min'] = df_test[pred_cols].min(axis=1)\n",
    "df_test['pred_mean'] = df_test[pred_cols].mean(axis=1)\n",
    "df_test['pred_std'] = df_test[pred_cols].std(axis=1)\n",
    "\n",
    "print(df_test['pred_std'].max(), df_test['pred_std'].min(), df_test['pred_std'].mean())\n",
    "\n",
    "df_test['smishing'] = df_test['pred_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T08:25:14.901Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test['smishing'].hist(bins=100, figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T08:25:14.903Z"
    }
   },
   "outputs": [],
   "source": [
    "for c in pred_cols:\n",
    "    print(c)\n",
    "    display((df_test[c] * 10).astype(int).value_counts(sort=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T08:25:14.904Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 0     1504\n",
    "# 1       11\n",
    "# 2        6\n",
    "# 3        6\n",
    "# 4        2\n",
    "# 5        3\n",
    "# 6        2\n",
    "# 9       39\n",
    "# 10      53\n",
    "(df_test['smishing'] * 10).astype(int).value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T08:25:14.905Z"
    }
   },
   "outputs": [],
   "source": [
    "model_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T08:25:14.907Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test[['smishing']].to_csv('submit/{}_nn.csv'.format(model_ts), index=True)\n",
    "# df_test[['id', 'smishing', 'text']].sort_values('smishing', ascending=False).to_csv('{}_text.csv'.format(model_ts), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dtoNNPnG75fT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mecab_tfidf.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
