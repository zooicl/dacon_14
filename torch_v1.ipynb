{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T12:38:46.791329Z",
     "start_time": "2019-12-29T12:38:46.220802Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1590,
     "status": "ok",
     "timestamp": 1576286906380,
     "user": {
      "displayName": "주이클",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCWVh4nvn9788qUddhoWTl5qQoYt0bzVMDlJWUumTg=s64",
      "userId": "02708070532256873610"
     },
     "user_tz": -540
    },
    "id": "U3xmRNtgpZwi",
    "outputId": "f6e95e03-5913-4a53-9ff3-1b6cde1b5a82"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.externals import joblib \n",
    "import os\n",
    "from konlpy.tag import Mecab\n",
    "import lightgbm as lgb\n",
    "print(lgb.__version__)\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.externals import joblib \n",
    "\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T12:38:46.977581Z",
     "start_time": "2019-12-29T12:38:46.792219Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### eval_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T12:38:46.982614Z",
     "start_time": "2019-12-29T12:38:46.978753Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval_summary(y_true, y_score, cut_off=0.5):\n",
    "    if len(y_true) == 0 or len(y_score) == 0:\n",
    "        return 'zero length'\n",
    "    if len(y_true) != len(y_score):\n",
    "        return 'diff length'\n",
    "    \n",
    "    y_pred = y_score.copy()\n",
    "    y_pred[y_pred > cut_off] = 1\n",
    "    y_pred[y_pred <= cut_off] = 0\n",
    "\n",
    "    eval_dict = {}\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score, pos_label=1)\n",
    "    \n",
    "    eval_dict['auc'] = metrics.auc(fpr, tpr)\n",
    "    eval_dict['confusion_matrix'] = metrics.confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    pre, rec, _, _ = metrics.precision_recall_fscore_support(y_true, y_pred, pos_label=1)\n",
    "    eval_dict['precision'] = pre[1]\n",
    "    eval_dict['recall'] = rec[1]\n",
    "    \n",
    "    return eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T12:38:46.991030Z",
     "start_time": "2019-12-29T12:38:46.983475Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "def show_gpu(msg):\n",
    "    \"\"\"\n",
    "    ref: https://discuss.pytorch.org/t/access-gpu-memory-usage-in-pytorch/3192/4\n",
    "    \"\"\"\n",
    "    def query(field):\n",
    "        return(subprocess.check_output(\n",
    "            ['nvidia-smi', f'--query-gpu={field}',\n",
    "                '--format=csv,nounits,noheader'], \n",
    "            encoding='utf-8'))\n",
    "    def to_int(result):\n",
    "        return int(result.strip().split('\\n')[0])\n",
    "    \n",
    "    used = to_int(query('memory.used'))\n",
    "    total = to_int(query('memory.total'))\n",
    "    pct = used / total\n",
    "    print('\\n' + msg, f'{100*pct:2.1f}% ({used} out of {total})')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T12:38:46.996796Z",
     "start_time": "2019-12-29T12:38:46.992134Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import gc\n",
    "\n",
    "# for tracked_object in gc.get_objects():\n",
    "#     if torch.is_tensor(tracked_object):\n",
    "#         print(\"{} {} {}\".format(\n",
    "#             type(tracked_object).__name__,\n",
    "#            \"GPU\" if tracked_object.is_cuda else \"\" ,\n",
    "#           \" pinned\" if tracked_object.is_pinned() else \"\",\n",
    "# ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T12:38:47.003436Z",
     "start_time": "2019-12-29T12:38:46.997824Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_train_data():\n",
    "    print('predict_train_data ...')\n",
    "    with torch.no_grad(): \n",
    "        model.eval()\n",
    "        y_true_list = []\n",
    "        y_score_list = []\n",
    "\n",
    "        for i, data in enumerate(train_loader):\n",
    "            X_batch, y_batch = data\n",
    "\n",
    "            y_true = y_batch\n",
    "            y_true_list.append(y_true[:, 1].cpu().detach().numpy())\n",
    "\n",
    "#             X_batch = torch.Tensor(X_batch.float()).type(dtype=torch.float32).to(device)\n",
    "#             y_batch = torch.Tensor(y_batch.float()).type(dtype=torch.float32).to(device)\n",
    "            \n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            \n",
    "            y_pred = torch.sigmoid(y_pred)\n",
    "            y_score_list.append(y_pred[:, 1].cpu().detach().numpy())\n",
    "            \n",
    "            del X_batch, y_batch, y_pred\n",
    "        \n",
    "        \n",
    "        return np.concatenate(y_true_list, axis=0), np.concatenate(y_score_list, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T12:38:47.013278Z",
     "start_time": "2019-12-29T12:38:47.004496Z"
    }
   },
   "outputs": [],
   "source": [
    "class DNNModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, dropout_probability=0.3):\n",
    "        super(DNNModel,self).__init__()\n",
    "        relu = torch.nn.ReLU()\n",
    "        dropout = torch.nn.Dropout(p=dropout_probability)\n",
    "\n",
    "        self.model = torch.nn.Sequential(\n",
    "#             torch.nn.Linear(input_size, 4096), torch.nn.ReLU(), dropout,\n",
    "#             torch.nn.Linear(4096, 2048), torch.nn.ReLU(), dropout,\n",
    "            torch.nn.Linear(input_size, 1024), relu, torch.nn.BatchNorm1d(1024), dropout, \n",
    "            torch.nn.Linear(1024, 512), relu, torch.nn.BatchNorm1d(512), dropout,\n",
    "            torch.nn.Linear(512, 256), relu, torch.nn.BatchNorm1d(256), dropout,\n",
    "            torch.nn.Linear(256, 128), relu, torch.nn.BatchNorm1d(128), dropout,\n",
    "            torch.nn.Linear(128, 2), \n",
    "#             torch.nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):        \n",
    "        return self.model(x) \n",
    "\n",
    "class KBDataset(Dataset):\n",
    "    def __init__(self, file_path, y_col, pos_only=False):\n",
    "#         df = pd.read_pickle(file_path)\n",
    "        df = joblib.load(file_path) \n",
    "        print(df.shape)\n",
    "        print(df.info())\n",
    "        \n",
    "        self.columns = [c for c in df.columns if c not in [y_col, 'id']]\n",
    "        self.X = df[self.columns].values\n",
    "        self.y = pd.get_dummies(df[y_col], prefix=y_col).values\n",
    "        \n",
    "        if pos_only:\n",
    "            self.X = self.X[df[y_col] == 1]\n",
    "            self.y = self.y[df[y_col] == 1]\n",
    "            print('pos only')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        return self.columns\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx].astype(np.float32), self.y[idx].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T12:38:47.028402Z",
     "start_time": "2019-12-29T12:38:47.014082Z"
    }
   },
   "outputs": [],
   "source": [
    "merged_ts = '20191229T155539'\n",
    "train_path = 'data/df_merged_{}_train.pkl'.format(merged_ts)\n",
    "test_path = 'data/df_merged_{}_test.pkl'.format(merged_ts)\n",
    "\n",
    "df_test = joblib.load(test_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T12:38:49.810118Z",
     "start_time": "2019-12-29T12:38:47.030136Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = KBDataset(train_path, 'smishing')\n",
    "train_size = len(dataset)\n",
    "fea_cols = dataset.get_feature_names()\n",
    "\n",
    "# model_ts = datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "model = DNNModel(input_size=len(fea_cols), dropout_probability=0.7).to(device)\n",
    "epoch = 1\n",
    "print(summary(model, (len(fea_cols), )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T12:38:49.813667Z",
     "start_time": "2019-12-29T12:38:49.811163Z"
    }
   },
   "outputs": [],
   "source": [
    "# criterion = torch.nn.BCELoss(reduction='mean').to(device)\n",
    "pos_weight = torch.Tensor([1., 50.,])\n",
    "# pos_weight = torch.Tensor([1., 1.,])\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='sum', pos_weight=pos_weight).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T12:38:49.826600Z",
     "start_time": "2019-12-29T12:38:49.814846Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=dataset,\n",
    "#                           batch_size=100000,\n",
    "#                         batch_size=int(train_size * 0.7),\n",
    "                          batch_size=train_size // 16,\n",
    "#                           batch_size=10000,\n",
    "                          shuffle=True,\n",
    "                          num_workers=16,\n",
    "                         drop_last=True\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T12:38:51.240656Z",
     "start_time": "2019-12-29T12:38:49.827922Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_pos = KBDataset(train_path, 'smishing', pos_only=True)\n",
    "train_pos_loader = DataLoader(dataset=dataset_pos,\n",
    "                          batch_size=len(dataset_pos),\n",
    "                          shuffle=True,\n",
    "                          num_workers=0,\n",
    "                         drop_last=True\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T12:39:14.964181Z",
     "start_time": "2019-12-29T12:38:51.241652Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_ts = datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "print(model_ts)\n",
    "print('epoch:', epoch)\n",
    "total_epoch = 20\n",
    "print('# of train_loader:', len(train_loader))\n",
    "\n",
    "for e in tqdm_notebook(range(epoch, epoch + total_epoch), total=total_epoch, desc = 'epoch'):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "#     for i, data in enumerate(train_pos_loader):\n",
    "#     for i, data in tqdm_notebook(enumerate(train_loader), total=len(train_loader), desc = 'epoch{}_batch'.format(e)):\n",
    "#         print(e, i)\n",
    "        X_batch, y_batch = data\n",
    "        \n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        y_pred = model(X_batch)\n",
    "        print(y_pred, y_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "\n",
    "        total_loss = total_loss + loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        del X_batch, y_batch, y_pred\n",
    "        gc.collect()\n",
    "\n",
    "    print(e-1, 'loss_sum', total_loss)\n",
    "    \n",
    "    if e % 10 == 0:\n",
    "        print('epoch', e)\n",
    "        y_true, y_score = predict_train_data()\n",
    "        print(eval_summary(y_true, y_score, cut_off=0.5))\n",
    "\n",
    "torch.save(model.state_dict(), 'model/{}_{}.model'.format(model_ts, epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T09:51:08.317463Z",
     "start_time": "2019-12-29T09:51:08.103502Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.Series(y_score)\n",
    "df.hist(bins=100, figsize=(20, 5))\n",
    "(df * 10).astype(int).value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T09:51:08.319914Z",
     "start_time": "2019-12-29T09:51:08.318434Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_model[(y_score <= 0.5) & (y_true == 1)]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T09:51:08.327898Z",
     "start_time": "2019-12-29T09:51:08.320710Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_model[(y_score > 0.5) & (y_true == 0)]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T09:51:08.551956Z",
     "start_time": "2019-12-29T09:51:08.328786Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test = torch.Tensor(df_test[fea_cols].values).to(device)\n",
    "df_test['smishing'] = torch.sigmoid(model(x_test))[:, 1].cpu().detach().numpy()\n",
    "df_test['smishing'].hist(bins=100, figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T09:51:08.555805Z",
     "start_time": "2019-12-29T09:51:08.552636Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 0     1504\n",
    "# 1       11\n",
    "# 2        6\n",
    "# 3        6\n",
    "# 4        2\n",
    "# 5        3\n",
    "# 6        2\n",
    "# 9       39\n",
    "# 10      53\n",
    "(df_test['smishing'] * 10).astype(int).value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T09:51:41.680927Z",
     "start_time": "2019-12-29T09:51:41.677911Z"
    }
   },
   "outputs": [],
   "source": [
    "model_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T09:51:42.309445Z",
     "start_time": "2019-12-29T09:51:42.291375Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test[['smishing']].to_csv('{}.csv'.format(model_ts), index=True)\n",
    "# df_test[['id', 'smishing', 'text']].sort_values('smishing', ascending=False).to_csv('{}_text.csv'.format(model_ts), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dtoNNPnG75fT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mecab_tfidf.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
