{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T01:04:54.303909Z",
     "start_time": "2019-12-27T01:04:53.718090Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1590,
     "status": "ok",
     "timestamp": 1576286906380,
     "user": {
      "displayName": "주이클",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCWVh4nvn9788qUddhoWTl5qQoYt0bzVMDlJWUumTg=s64",
      "userId": "02708070532256873610"
     },
     "user_tz": -540
    },
    "id": "U3xmRNtgpZwi",
    "outputId": "f6e95e03-5913-4a53-9ff3-1b6cde1b5a82"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiden/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.2\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.externals import joblib \n",
    "import os\n",
    "from konlpy.tag import Mecab\n",
    "import lightgbm as lgb\n",
    "print(lgb.__version__)\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T01:04:55.473454Z",
     "start_time": "2019-12-27T01:04:54.305070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aiden/src/dacon_14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(297571, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "\n",
    "base_path = '.'\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(base_path , 'input/train.csv'), index_col=0)\n",
    "df_test = pd.read_csv(os.path.join(base_path , 'input/public_test.csv'), index_col=0)\n",
    "df_test['smishing'] = -1\n",
    "\n",
    "df_fea = pd.concat([df_train, df_test])\n",
    "df_fea.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T01:05:07.121434Z",
     "start_time": "2019-12-27T01:05:04.829394Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "uquxguHUpZwt"
   },
   "outputs": [],
   "source": [
    "# mecab = Mecab()\n",
    "# # df_space['morphs'] = df_space['spacing'].apply(lambda x: mecab.morphs(x))\n",
    "# df_fea['nouns'] = df_fea['text'].apply(lambda x: mecab.nouns(x))\n",
    "\n",
    "# df_fea['nouns_str'] = df_fea['nouns'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# df_fea.to_pickle('df_fea.pkl')\n",
    "\n",
    "df_fea = pd.read_pickle('data/df_fea.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T01:05:13.220279Z",
     "start_time": "2019-12-27T01:05:07.122439Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297571, 860)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=0.25, min_df=50)\n",
    "\n",
    "vectorizer = vectorizer.fit(df_fea[df_fea['smishing']==1]['nouns_str'].values)\n",
    "cnt_vec = vectorizer.transform(df_fea['nouns_str'].values).toarray()\n",
    "\n",
    "cnt_dict = {'cnt_{0:03d}'.format(i):'cnt_{0:03d}_{1}'.format(i, c) for i, c in enumerate(vectorizer.get_feature_names())}\n",
    "cnt_cols = sorted(cnt_dict.keys())\n",
    "\n",
    "df_cnt_vec = pd.DataFrame(cnt_vec, columns=cnt_cols, dtype=np.uint8)\n",
    "df_cnt_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T01:05:26.210072Z",
     "start_time": "2019-12-27T01:05:13.221279Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "l2Dgkdt6pZw_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297571, 2900)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_size = None\n",
    "stop_words = [\n",
    "#    '은행',\n",
    "#     '고객',\n",
    "#     '가능',\n",
    "#     '전화',\n",
    "#     '기간',\n",
    "#     '대출',\n",
    "#     '금리',\n",
    "#     '상담',\n",
    "#     '광고',\n",
    "#     '상품',\n",
    "#     '센터',\n",
    "]\n",
    "vectorizer = TfidfVectorizer(max_features=tfidf_size, \n",
    "                             stop_words=stop_words, \n",
    "                             max_df=0.5,\n",
    "                             min_df=100)\n",
    "\n",
    "# vectorizer = vectorizer.fit(df_fea[df_fea['smishing']==1]['nouns_str'].values)\n",
    "vectorizer = vectorizer.fit(df_fea['nouns_str'].values)\n",
    "\n",
    "tfidf = vectorizer.transform(df_fea['nouns_str'].values).toarray()\n",
    "tfidf_dict = {'tfidf_{0:03d}'.format(v):'tfidf_{0:03d}_{1}'.format(v, k) for k, v in sorted(vectorizer.vocabulary_.items(), key=lambda item: item[1])}\n",
    "tfidf_cols = sorted(tfidf_dict.keys())\n",
    "\n",
    "df_tfidf = pd.DataFrame(tfidf, columns=tfidf_cols, dtype=np.float16)\n",
    "df_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T01:05:35.649262Z",
     "start_time": "2019-12-27T01:05:26.210894Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297571, 2773)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=tfidf_size, \n",
    "                             stop_words=stop_words, \n",
    "                            # max_df=0.5,min_df=100\n",
    "                            )\n",
    "\n",
    "vectorizer = vectorizer.fit(df_fea[df_fea['smishing']==1]['nouns_str'].values)\n",
    "# vectorizer = vectorizer.fit(df_fea['nouns_str'].values)\n",
    "\n",
    "tfidf = vectorizer.transform(df_fea['nouns_str'].values).toarray()\n",
    "tfidf2_dict = {'tfidf2_{0:03d}'.format(v):'tfidf2_{0:03d}_{1}'.format(v, k) for k, v in sorted(vectorizer.vocabulary_.items(), key=lambda item: item[1])}\n",
    "tfidf2_cols = sorted(tfidf2_dict.keys())\n",
    "\n",
    "df_tfidf2 = pd.DataFrame(tfidf, columns=tfidf2_cols, dtype=np.float16)\n",
    "df_tfidf2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T01:05:45.764159Z",
     "start_time": "2019-12-27T01:05:35.650081Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 185503,
     "status": "ok",
     "timestamp": 1576287090605,
     "user": {
      "displayName": "주이클",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCWVh4nvn9788qUddhoWTl5qQoYt0bzVMDlJWUumTg=s64",
      "userId": "02708070532256873610"
     },
     "user_tz": -540
    },
    "id": "4f9oWotspZxF",
    "outputId": "6e0f2830-c6ef-4e00-9b0b-19ea6751dad0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297571, 5) (297571, 860) (297571, 2900) (297571, 2773)\n",
      "(297571, 6539)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 297571 entries, 0 to 297570\n",
      "Columns: 6539 entries, id to tfidf2_999\n",
      "dtypes: float16(5673), int64(2), object(4), uint8(860)\n",
      "memory usage: 3.4+ GB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year_month</th>\n",
       "      <th>text</th>\n",
       "      <th>smishing</th>\n",
       "      <th>nouns</th>\n",
       "      <th>nouns_str</th>\n",
       "      <th>cnt_000</th>\n",
       "      <th>cnt_001</th>\n",
       "      <th>cnt_002</th>\n",
       "      <th>cnt_003</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf2_990</th>\n",
       "      <th>tfidf2_991</th>\n",
       "      <th>tfidf2_992</th>\n",
       "      <th>tfidf2_993</th>\n",
       "      <th>tfidf2_994</th>\n",
       "      <th>tfidf2_995</th>\n",
       "      <th>tfidf2_996</th>\n",
       "      <th>tfidf2_997</th>\n",
       "      <th>tfidf2_998</th>\n",
       "      <th>tfidf2_999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>XXX은행성산XXX팀장입니다.행복한주말되세요</td>\n",
       "      <td>0</td>\n",
       "      <td>[행성, 산, 팀장, 행복, 주말]</td>\n",
       "      <td>행성 산 팀장 행복 주말</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>오늘도많이웃으시는하루시작하세요XXX은행 진월동VIP라운지 XXX올림</td>\n",
       "      <td>0</td>\n",
       "      <td>[오늘, 하루, 시작, 은행, 진월동, 라운지]</td>\n",
       "      <td>오늘 하루 시작 은행 진월동 라운지</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>안녕하십니까 고객님. XXX은행입니다.금일 납부하셔야 할 금액은 153600원 입니...</td>\n",
       "      <td>0</td>\n",
       "      <td>[안녕, 고객, 은행, 금일, 납부, 금액, 원, 감사, 새해, 복, 은행, 옥포]</td>\n",
       "      <td>안녕 고객 은행 금일 납부 금액 원 감사 새해 복 은행 옥포</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>XXX 고객님안녕하세요XXX은행 XXX지점입니다지난 한 해 동안 저희 XXX지점에 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[고객, 안녕, 은행, 지점, 해, 동안, 저희, 지점, 성원, 감사, 시작, 년,...</td>\n",
       "      <td>고객 안녕 은행 지점 해 동안 저희 지점 성원 감사 시작 년 소망 일 고객 가정 건...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>1월은 새로움이 가득XXX입니다.올 한해 더 많이행복한 한해되시길바랍니다</td>\n",
       "      <td>0</td>\n",
       "      <td>[월, 한, 행복, 해]</td>\n",
       "      <td>월 한 행복 해</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>행복한주말보내세요XXX용현남전담직원대리 XXX올림</td>\n",
       "      <td>0</td>\n",
       "      <td>[행복, 주말, 현남, 전담, 직원, 대리]</td>\n",
       "      <td>행복 주말 현남 전담 직원 대리</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>XXX 고객님 안녕하세요XXX은행 무교지점 XXX과장입니다 오늘 아침에 눈을 뜨니 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[고객, 안녕, 은행, 무교, 지점, 과장, 아침, 눈, 눈, 세상, 적, 눈, 눈...</td>\n",
       "      <td>고객 안녕 은행 무교 지점 과장 아침 눈 눈 세상 적 눈 눈 순간 출근 걱정 어른 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>XXX 고객님지난 한해 베풀어 주신 은혜 진심으로 감사 드립니다.가슴 깊이 간직 하...</td>\n",
       "      <td>0</td>\n",
       "      <td>[고객, 한, 은혜, 진심, 감사, 가슴, 간직, 정유, 년, 새해, 가족, 행복,...</td>\n",
       "      <td>고객 한 은혜 진심 감사 가슴 간직 정유 년 새해 가족 행복 뜻 바 진심 소망 은행...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>설연휴 가족들과 훈훈한 정 나누시고 정겨운추억 많이 만드세요XXX오XXX올림</td>\n",
       "      <td>0</td>\n",
       "      <td>[설, 연휴, 가족, 정, 추억, 오]</td>\n",
       "      <td>설 연휴 가족 정 추억 오</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>(광고)XXXBaXXX고객님들 뒤엔XXX 언제나 XXX새로운 마음가짐으로 새롭게 준...</td>\n",
       "      <td>1</td>\n",
       "      <td>[광고, 고객, 뒤, 마음가짐, 준비, 당, 행상, 품, 자격, 기준, 심사, 기준...</td>\n",
       "      <td>광고 고객 뒤 마음가짐 준비 당 행상 품 자격 기준 심사 기준 완화 상품 상품 정보...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 6539 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id year_month                                               text  smishing  \\\n",
       "0   0    2017-01                           XXX은행성산XXX팀장입니다.행복한주말되세요         0   \n",
       "1   1    2017-01              오늘도많이웃으시는하루시작하세요XXX은행 진월동VIP라운지 XXX올림         0   \n",
       "2   2    2017-01  안녕하십니까 고객님. XXX은행입니다.금일 납부하셔야 할 금액은 153600원 입니...         0   \n",
       "3   4    2017-01  XXX 고객님안녕하세요XXX은행 XXX지점입니다지난 한 해 동안 저희 XXX지점에 ...         0   \n",
       "4   5    2017-01           1월은 새로움이 가득XXX입니다.올 한해 더 많이행복한 한해되시길바랍니다         0   \n",
       "5   6    2017-01                        행복한주말보내세요XXX용현남전담직원대리 XXX올림         0   \n",
       "6   7    2017-01  XXX 고객님 안녕하세요XXX은행 무교지점 XXX과장입니다 오늘 아침에 눈을 뜨니 ...         0   \n",
       "7   8    2017-01  XXX 고객님지난 한해 베풀어 주신 은혜 진심으로 감사 드립니다.가슴 깊이 간직 하...         0   \n",
       "8   9    2017-01         설연휴 가족들과 훈훈한 정 나누시고 정겨운추억 많이 만드세요XXX오XXX올림         0   \n",
       "9  10    2017-01  (광고)XXXBaXXX고객님들 뒤엔XXX 언제나 XXX새로운 마음가짐으로 새롭게 준...         1   \n",
       "\n",
       "                                               nouns  \\\n",
       "0                                [행성, 산, 팀장, 행복, 주말]   \n",
       "1                         [오늘, 하루, 시작, 은행, 진월동, 라운지]   \n",
       "2     [안녕, 고객, 은행, 금일, 납부, 금액, 원, 감사, 새해, 복, 은행, 옥포]   \n",
       "3  [고객, 안녕, 은행, 지점, 해, 동안, 저희, 지점, 성원, 감사, 시작, 년,...   \n",
       "4                                      [월, 한, 행복, 해]   \n",
       "5                           [행복, 주말, 현남, 전담, 직원, 대리]   \n",
       "6  [고객, 안녕, 은행, 무교, 지점, 과장, 아침, 눈, 눈, 세상, 적, 눈, 눈...   \n",
       "7  [고객, 한, 은혜, 진심, 감사, 가슴, 간직, 정유, 년, 새해, 가족, 행복,...   \n",
       "8                              [설, 연휴, 가족, 정, 추억, 오]   \n",
       "9  [광고, 고객, 뒤, 마음가짐, 준비, 당, 행상, 품, 자격, 기준, 심사, 기준...   \n",
       "\n",
       "                                           nouns_str  cnt_000  cnt_001  \\\n",
       "0                                      행성 산 팀장 행복 주말        0        0   \n",
       "1                                오늘 하루 시작 은행 진월동 라운지        0        0   \n",
       "2                  안녕 고객 은행 금일 납부 금액 원 감사 새해 복 은행 옥포        0        0   \n",
       "3  고객 안녕 은행 지점 해 동안 저희 지점 성원 감사 시작 년 소망 일 고객 가정 건...        0        0   \n",
       "4                                           월 한 행복 해        0        0   \n",
       "5                                  행복 주말 현남 전담 직원 대리        0        0   \n",
       "6  고객 안녕 은행 무교 지점 과장 아침 눈 눈 세상 적 눈 눈 순간 출근 걱정 어른 ...        0        0   \n",
       "7  고객 한 은혜 진심 감사 가슴 간직 정유 년 새해 가족 행복 뜻 바 진심 소망 은행...        0        0   \n",
       "8                                     설 연휴 가족 정 추억 오        0        0   \n",
       "9  광고 고객 뒤 마음가짐 준비 당 행상 품 자격 기준 심사 기준 완화 상품 상품 정보...        0        0   \n",
       "\n",
       "   cnt_002  cnt_003  ...  tfidf2_990  tfidf2_991  tfidf2_992  tfidf2_993  \\\n",
       "0        0        0  ...         0.0         0.0         0.0         0.0   \n",
       "1        0        0  ...         0.0         0.0         0.0         0.0   \n",
       "2        0        0  ...         0.0         0.0         0.0         0.0   \n",
       "3        0        0  ...         0.0         0.0         0.0         0.0   \n",
       "4        0        0  ...         0.0         0.0         0.0         0.0   \n",
       "5        0        0  ...         0.0         0.0         0.0         0.0   \n",
       "6        0        0  ...         0.0         0.0         0.0         0.0   \n",
       "7        0        0  ...         0.0         0.0         0.0         0.0   \n",
       "8        0        0  ...         0.0         0.0         0.0         0.0   \n",
       "9        0        0  ...         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   tfidf2_994  tfidf2_995  tfidf2_996  tfidf2_997  tfidf2_998  tfidf2_999  \n",
       "0         0.0         0.0         0.0         0.0         0.0    0.000000  \n",
       "1         0.0         0.0         0.0         0.0         0.0    0.000000  \n",
       "2         0.0         0.0         0.0         0.0         0.0    0.000000  \n",
       "3         0.0         0.0         0.0         0.0         0.0    0.000000  \n",
       "4         0.0         0.0         0.0         0.0         0.0    0.000000  \n",
       "5         0.0         0.0         0.0         0.0         0.0    0.000000  \n",
       "6         0.0         0.0         0.0         0.0         0.0    0.000000  \n",
       "7         0.0         0.0         0.0         0.0         0.0    0.000000  \n",
       "8         0.0         0.0         0.0         0.0         0.0    0.000000  \n",
       "9         0.0         0.0         0.0         0.0         0.0    0.112427  \n",
       "\n",
       "[10 rows x 6539 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_fea.shape, df_cnt_vec.shape, df_tfidf.shape, df_tfidf2.shape)\n",
    "\n",
    "df_merged = pd.concat([df_fea.reset_index(), df_cnt_vec[cnt_cols], df_tfidf[tfidf_cols], df_tfidf2[tfidf2_cols]], axis=1)\n",
    "print(df_merged.shape)\n",
    "# df_merged = pd.concat([df_merged, df_tfidf[tfidf_cols]], axis=1)\n",
    "# print(df_merged.shape)\n",
    "\n",
    "print(df_merged.info())\n",
    "df_merged.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T01:05:45.783419Z",
     "start_time": "2019-12-27T01:05:45.765072Z"
    }
   },
   "outputs": [],
   "source": [
    "del df_fea, df_cnt_vec, df_tfidf, df_tfidf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T01:05:56.298085Z",
     "start_time": "2019-12-27T01:05:56.293175Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 185838,
     "status": "ok",
     "timestamp": 1576287091046,
     "user": {
      "displayName": "주이클",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCWVh4nvn9788qUddhoWTl5qQoYt0bzVMDlJWUumTg=s64",
      "userId": "02708070532256873610"
     },
     "user_tz": -540
    },
    "id": "QOi9dYzqpZxV",
    "outputId": "9ceb7e20-059e-4946-934e-ab85c98dca56",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5673"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = len(df_train)\n",
    "print(train_size)\n",
    "\n",
    "cat_cols = []\n",
    "fea_cols = cnt_cols + tfidf_cols + cat_cols + tfidf2_cols\n",
    "fea_cols = tfidf_cols + cat_cols + tfidf2_cols\n",
    "# fea_cols = cnt_cols + cat_cols\n",
    "# fea_cols = tfidf_cols + cat_cols\n",
    "len(fea_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T01:05:57.617362Z",
     "start_time": "2019-12-27T01:05:57.611706Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval_summary(y_true, y_score, cut_off=0.5):\n",
    "    y_pred = y_score.copy()\n",
    "    y_pred[y_pred > cut_off] = 1\n",
    "    y_pred[y_pred <= cut_off] = 0\n",
    "\n",
    "    eval_dict = {}\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score, pos_label=1)\n",
    "    \n",
    "    eval_dict['auc'] = metrics.auc(fpr, tpr)\n",
    "    eval_dict['confusion_matrix'] = metrics.confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    pre, rec, _, _ = metrics.precision_recall_fscore_support(y_true, y_pred, pos_label=1)\n",
    "    eval_dict['precision'] = pre[1]\n",
    "    eval_dict['recall'] = rec[1]\n",
    "    \n",
    "    return eval_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torch RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T01:06:03.107023Z",
     "start_time": "2019-12-27T01:06:02.494188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.1\n",
      "GeForce RTX 2070 SUPER\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T00:55:39.951Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,input_size,embed_size,hidden_size,output_size,num_layers=1,bidirec=False):\n",
    "        super(RNN,self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        if bidirec:\n",
    "            self.num_directions = 2\n",
    "        else:\n",
    "            self.num_directions = 1\n",
    "            \n",
    "        self.embed = nn.Embedding(input_size,embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size,hidden_size,num_layers,batch_first=True,bidirectional=bidirec)\n",
    "        self.linear = nn.Linear(hidden_size*self.num_directions,output_size)\n",
    "        \n",
    "    def init_hidden(self,batch_size):\n",
    "        # (num_layers * num_directions, batch_size, hidden_size)\n",
    "        hidden = Variable(torch.zeros(self.num_layers*self.num_directions,batch_size,self.hidden_size))\n",
    "        cell = Variable(torch.zeros(self.num_layers*self.num_directions,batch_size,self.hidden_size))\n",
    "        return hidden, cell\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        \"\"\"\n",
    "        inputs : B,T\n",
    "        \"\"\"\n",
    "        embed = self.embed(inputs) # word vector indexing\n",
    "        hidden, cell = self.init_hidden(inputs.size(0)) # initial hidden,cell\n",
    "        \n",
    "        output, (hidden,cell) = self.lstm(embed,(hidden,cell))\n",
    "        \n",
    "        # Many-to-Many\n",
    "        output = self.linear(output) # B,T,H -> B,T,V\n",
    "        \n",
    "        # Many-to-One\n",
    "        #hidden = hidden[-self.num_directions:] # (num_directions,B,H)\n",
    "        #hidden = torch.cat([h for h in hidden],1)\n",
    "        #output = self.linear(hidden) # last hidden\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T00:55:39.952Z"
    }
   },
   "outputs": [],
   "source": [
    "# del model, x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T00:55:39.954Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.init()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T00:55:39.956Z"
    }
   },
   "outputs": [],
   "source": [
    "model_ts = datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "x_data = torch.Tensor(df_merged[:train_size][fea_cols].values).to(device)\n",
    "y_data = torch.Tensor(df_merged[:train_size][['smishing']].values).to(device)\n",
    "\n",
    "model = MyModel()\n",
    "model.to(device)\n",
    "\n",
    "criterion = torch.nn.BCELoss(size_average=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T00:55:39.963Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e in range(epoch, epoch + 500000):\n",
    "    y_pred = model(x_data)\n",
    "    \n",
    "    loss = criterion(y_pred, y_data)\n",
    "\n",
    "    if e % 100 == 0:\n",
    "        print(e, loss.item())\n",
    "        \n",
    "    if e % 10000 == 0:\n",
    "        y_score = model(x_data).cpu().detach().numpy().reshape(1, -1)[0]\n",
    "        print(eval_summary(df_merged[:train_size]['smishing'].values, y_score, cut_off=0.5))\n",
    "        \n",
    "        x_test = torch.Tensor(df_merged[train_size:][fea_cols].values).to(device)\n",
    "        df_test['smishing_{}'.format(e)] = model(x_test).cpu().detach().numpy().reshape(1, -1)[0]\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    epoch = e\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T00:55:39.965Z"
    }
   },
   "outputs": [],
   "source": [
    "y_score = model(x_data).cpu().detach().numpy().reshape(1, -1)[0]\n",
    "eval_summary(df_merged[:train_size]['smishing'].values, y_score, cut_off=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T00:55:39.967Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test = torch.Tensor(df_merged[train_size:][fea_cols].values).to(device)\n",
    "pred = model(x_test).cpu().detach().numpy().reshape(1, -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T00:55:39.969Z"
    }
   },
   "outputs": [],
   "source": [
    "model_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T00:55:39.971Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test['smishing'] = pred\n",
    "df_test['smishing'].hist(bins=100, figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T00:55:39.972Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model/torch_lr.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-27T00:55:39.974Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test[['id', 'smishing']].to_csv('torch_lr_{}.csv'.format(lgb_ts), index=False)\n",
    "df_test[['id', 'smishing', 'text']].sort_values('smishing', ascending=False).to_csv('torch_lr_{}_text.csv'.format(model_ts), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dtoNNPnG75fT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mecab_tfidf.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
